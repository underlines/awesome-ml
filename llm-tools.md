[üè†Home](README.md)

# Open LLM Models

- Want to know which one is "the best"? Have a look at the [üèÜ Leaderboards](llm-tools.md#benchmarking) in the Benchmarking section.
- [llm.extractum.io](https://llm.extractum.io/) The LLM Explorer, a Large Language Model Directory with filters for trending, downloads and latest showing details like quantizations, model types and sizes
- [can-it-run-llm](https://huggingface.co/spaces/Vokturz/can-it-run-llm) Check most Huggingface LLMs and quants for hardware requirements like vram, ram and memory requirements

# Tools

## Native GUIs

- [chatgptui/desktop](https://github.com/chatgptui/desktop)
- [chatbox](https://github.com/Bin-Huang/chatbox) is a Windows, Mac & Linux native ChatGPT Client
- [BingGPT](https://github.com/dice2o/BingGPT) Desktop application of new Bing's AI-powered chat
- [cheetah](https://github.com/leetcode-mafia/cheetah) Speech to text for remote coding interviews, giving you hints from GTP3/4
- [Chat2DB++](https://github.com/chat2db/Chat2DB) general-purpose SQL & multi DBMS client and reporting tool which uses ChatGPT capabilities to write and optimize Queries
- [ChatGPT-Next-Web](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) Web, Windows, Linux, Mac GUI. Supports: Local LLMs, Markdown, LaTex, mermaid, code, history compression, prompt templates
- [ChatGPT](https://github.com/HemulGM/ChatGPT) Native Application for Windows, Mac, Android, iOS, Linux
- [koboldcpp](https://github.com/LostRuins/koboldcpp) llama.cpp with a fancy UI, persistent stories, editing tools, memory etc. Supporting ggmlv3 and old ggml, CLBlast and llama, RWKV, GPT-NeoX, Pythia models
- [Serge](https://github.com/nsarrazin/serge) chat interface based on llama.cpp for running Alpaca models. Entirely self-hosted, no API keys needed
- [faraday.dev](https://faraday.dev/) using llama.cpp under the hood to run most llama based models, made for character based chat and role play
- [gpt4all](https://github.com/nomic-ai/gpt4all) terminal and gui version to run local gpt-j models, [compiled binaries for win/osx/linux](https://gpt4all.io/index.html)
- [gpt4all.zig](https://github.com/renerocksai/gpt4all.zig) terminal version of GPT4All
- [gpt4all-chat](https://github.com/nomic-ai/gpt4all-chat) Cross platform desktop GUI for GPT4All  models (gpt-j)
- [ollama](https://github.com/jmorganca/ollama) Run, create, and share llms on macOS, win/linux with a simple cli interface and portable modelfile package
- [LM Studio](https://lmstudio.ai/) closed-source but very easy to use Native Mac, Windows, Linux GUI, supporting ggml, MPT, StarCoder, Falcon, Replit, GPT-Neu-X, gguf
  - [lms](https://github.com/lmstudio-ai/lms) CLI version of LMStudio
- [pinokio](https://pinokio.computer/) Template based 1 Click installer for ML inference (LLMs, Audio, Text, Video)
- [Lit-llama](https://github.com/Lightning-AI/lit-llama) training, fine tuning and inference of llama
- [Dalai](https://github.com/cocktailpeanut/dalai) LLaMA-based ChatGPT for single GPUs
- [ChatLLaMA](https://github.com/juncongmoo/chatllama) LLaMA-based ChatGPT for single GPUs
- [mlc-llm](https://github.com/mlc-ai/mlc-llm), run any LLM on any hardware (iPhones, Android, Win, Linux, Mac, WebGPU, Metal. NVidia, AMD)
- [webllm](https://github.com/mlc-ai/web-llm) Web LLM running LLMs with WebGPU natively in the browser using local GPU acceleration, without any backend, [demo](https://webllm.mlc.ai/)
- [faraday.dev](https://faraday.dev/) Run open-source LLMs on your Win/Mac. Completely offline. Zero configuration.
- [ChatALL](https://github.com/sunner/ChatALL) concurrently sends prompts to multiple LLM-based AI bots both local and APIs and displays the results
- [pyllama](https://github.com/juncongmoo/pyllama) hacked version of LLaMA based on Meta's implementation, optimized for Single GPUs
- [gmessage](https://github.com/drbh/gmessage) visually pleasing chatbot that uses a locally running LLM server and supports multiple themes, chat history search, text to speech, JSON file export, and OpenAI API compatible Python code
- [selfhostedAI](https://github.com/josStorer/selfhostedAI) one-click deployment of RWKV, ChatGLM, llama.cpp models for substituting the openAI API to a locally hosted API
- [Lit-GPT](https://github.com/Lightning-AI/lit-gpt) run SOTA LLMs, supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed
- [text-generation-inference](https://github.com/huggingface/text-generation-inference) Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets
- [minigpt4.cpp](https://github.com/Maknee/minigpt4.cpp) to run minigpt4 using 4-bit quantization with using the ggml library in pure C/C++
- [Windows AI Studio](https://github.com/microsoft/windows-ai-studio) Visual Studio Code extension for Fine-tuning, RAG development and inference of local models
- [jan](https://github.com/janhq/jan) an open source alternative to ChatGPT that runs 100% offline on Windows, Intel/Apple Silicon Mac, Linux and Mobile
- [open-interpreter](https://github.com/KillianLucas/open-interpreter) lets LLMs run code (Python, Javascript, Shell, and more) locally. You can chat with Open Interpreter through a ChatGPT-like interface in your terminal
- [ClipboardConqueror](https://github.com/aseichter2007/ClipboardConqueror) a novel omnipresent copilot alternative designed to bring your very own LLM AI assistant to any text field
- [Chat With RTX](https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/) by NVIDIA using Tensore Cores locally to run LLMs fast with a local RAG workflow.
- [msty](https://msty.app/) offline-first closed source (but free) GUI with support for llama, mixtral, qwen, llava, gemma and online APIs like openai, gemini, groq, claude etc with advanced features like split chat, in chat editing, prompt templates, sticky prompt
- [singulatron](https://singulatron.com/desktop-ai) simple interface to download and run LLMs, similar to LM Studio

## Web GUIs

- [enricoros/nextjs-chatgpt-app](https://github.com/enricoros/nextjs-chatgpt-app)
- [no8081/chatgpt-demo](https://github.com/ddiu8081/chatgpt-demo)
- [IPython-gpt](https://github.com/santiagobasulto/ipython-gpt) use chatGPT directly inside jupyter notebooks
- [Chatbot UI](https://github.com/mckaywrigley/chatbot-ui) An open source ChatGPT UI
- [freegpt-webui](https://github.com/ramonvc/freegpt-webui) provides a user friendly web-interface connecting to free (reverse-engineered) public GPT3.5/GPT4 endpoints using gpt4free
- [Flux](https://github.com/paradigmxyz/flux) Graph-based LLM power tool for exploring many prompts and completions in parallel.
- [Text Generation Webui](https://github.com/oobabooga/text-generation-webui) An all purpose UI to run LLMs of all sorts with optimizations ([running LLaMA-13b on 6GB VRAM](https://gist.github.com/rain-1/8cc12b4b334052a21af8029aa9c4fafc), [HN Thread](https://news.ycombinator.com/item?id=35937505))
- [Text Generation Webui Ph0rk0z fork](https://github.com/Ph0rk0z/text-generation-webui-testing/) supporting all GPTQ versions and max context of 8192 instead of 4096 (because some models support longer context now)
- [dockerLLM](https://github.com/TheBlokeAI/dockerLLM/tree/main) TheBloke's docker variant of text-generation-webui
- [lollms-webui](https://github.com/ParisNeo/lollms-webui) former GPT4ALL-UI by ParisNeo, user friendly all-in-one interface, with bindings for c_transformers, gptq, gpt-j, llama_cpp, py_llama_cpp, ggml
- [Alpaca-LoRa-Serve](https://github.com/deep-diver/Alpaca-LoRA-Serve)
- [chat petals](https://github.com/borzunov/chat.petals.ml) web app + HTTP and Websocket endpoints for BLOOM-176B inference with the Petals client
- [Alpaca-Turbo](https://github.com/ViperX7/Alpaca-Turbo) Web UI to run alpaca model locally on Win/Mac/Linux
- [FreedomGPT](https://github.com/ohmplatform/FreedomGPT) Web app that executes the FreedomGPT LLM locally
- [HuggingChat](https://huggingface.co/chat) open source chat interface for transformer based LLMs by Huggingface
- [openplayground](https://github.com/nat/openplayground) enables running LLM models on a laptop using a full UI, supporting various APIs and local HuggingFace cached models
- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) Easy installation and running of RWKV Models, providing a local OpenAI API, GUI and custom CUDA kernel acceleration. Supports 2gb up to 32gb VRAM
- [BrainChulo](https://github.com/ChuloAI/BrainChulo) Chat App with vector based Long-Term Memory supporting one-shot, few-shot and Tool capable agents
- [biniou](https://github.com/Woolverine94/biniou) a self-hosted webui for 30+ generative ai models for text generation, image generation, audio generation, video generation etc.
- [ExUI](https://github.com/turboderp/exui) simple, lightweight web UI for running local inference using ExLlamaV2
- [ava](https://github.com/cztomsik/ava) Air-gapped Virtual Assistant / Personal Language Server with support for local models using llama.cpp as a backend, [demo](https://avapls.com/)
- [llamafile](https://github.com/Mozilla-Ocho/llamafile) Distribute and run LLMs with a single file on Windows, macOS, Linux
- [OpenChat](https://github.com/openchatai/OpenChat) web ui that currently supports openAI but will implement local LLM support, RAG with PDF, websites, confluence, office 365
- [lobe-chat](https://github.com/lobehub/lobe-chat) docker image based chat bot framework with plugin and agent support, roles, UI etc
- [LibreChat](https://github.com/danny-avila/LibreChat) OpenAI, Assistants API, Vision, Mistral, Bing, Anthropic, OpenRouter, Google Gemini, model switching, langchain, DALL-E, Plugins, OpenAI Functions, Multi-User, Presets
- [open-webui](https://github.com/open-webui/open-webui) formerly ollama webui, docker and kubernetes setup, code, MD, LaTeX formatting, local RAG feature, web browsing, RLHF annotation, prompt presets, model download and switching, multi modal support
- [ollama-ui](https://github.com/ollama-ui/ollama-ui) Simple HTML UI for Ollama
- [ollama-ui](https://github.com/ollama-webui/ollama-webui) ChatGPT-Style Responsive Chat Web UI Client (GUI) for Ollama
- [big-AGI](https://github.com/enricoros/big-AGI) Web Browse, Search, Sharing, Tracking, supporting LocalAI, Ollama, LM Studio, Azure, Gemini, OpenAI, Groq, Mistral, OpenRouter etc.

## Backends

- [ExLlama](https://github.com/turboderp/exllama) a more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights. By [ReturningTarzan](https://www.reddit.com/r/LocalLLaMA/comments/13vm7tx/can_an_rtx_3090_run_a_30b_4bit_model_with_webui/jm6wmu0/)
- [ExLlamaV2](https://github.com/turboderp/exllamav2) faster ExLlama
- [transformers](https://github.com/huggingface/transformers) huggingface transformers
- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes) 8 bit inference
- [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) 4bit inference
- [llama.cpp](https://github.com/ggerganov/llama.cpp) C/C++ implementation providing inference for a wide range of LLM architectures like llama, mistral, dbrx, qwen, mamba, gemma and more, supporting a wide range of hardware, with optimizations for ARM, Apple Metal, x86. Offers various quantization techniques, CUDA kernels, Vulkan and SYCL backend support, and CPU+GPU hybrid inference for models larger than the total VRAM capacity
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) Python API for running LLMs on GPU with support for MHA, MQA, GQA, Tensor Parallelism, INT4/8 Quantization, GPTQ, AWQ, FP8, RoPE to run Baichuan, BLOOM, ChatGLM, Falcon, GPT-J/NeoX, LLaMA/2,MPT, OPT, SantaCoder, StarCoder etc.
- [tensorrtllm_backend](https://github.com/triton-inference-server/tensorrtllm_backend)  Triton TensorRT-LLM Backend
- [RWKV.cpp](https://github.com/saharNooby/rwkv.cpp) CPU only port of BlinkDL/RWKV-LM to ggerganov/ggml. Supports FP32, FP16 and quantized INT4.
- [sherpa](https://github.com/Bip-Rep/sherpa) llama.cpp on android
- [chatglm.cpp](https://github.com/li-plus/chatglm.cpp) C++ implementation of ChatGLM-6B & ChatGLM2-6B
- [MLX](https://github.com/ml-explore/mlx) Apple's ML Toolkit supporting Transformers in the MLX format for faster inference

## Voice Assistants

- [datafilik/GPT-Voice-Assistant](https://github.com/datafilik/GPT-Voice-Assistant)
- [Abdallah-Ragab/VoiceGPT](https://github.com/Abdallah-Ragab/VoiceGPT)
- [LlmKira/Openaibot](https://github.com/LlmKira/Openaibot)
- [BarkingGPT](https://github.com/BudEcosystem/BarkingGPT) Audio2Audio by using Whisper+chatGPT+Bark
- [gpt_chatbot](https://github.com/1nnovat1on/gpt_chatbot) Windows / elevenlabs TTS + pinecone long term memory
- [gpt-voice-conversation-chatbot](https://github.com/Adri6336/gpt-voice-conversation-chatbot) using GPT3.5/4 API, elevenlab voices, google tts, session long term memory
- [JARVIS-ChatGPT](https://github.com/gia-guar/JARVIS-ChatGPT) conversational assistant that uses OpenAI Whisper, OpenAI ChatGPT, and IBM Watson to provide quasi-real-time tips and opinions.
- [ALFRED](https://github.com/masrad/ALFRED) LangChain Voice Assistant, powered by GPT-3.5-turbo, whisper, Bark, pyttsx3 and more
- [bullerbot](https://github.com/EdwardIPAguilar/BuellerBot) uses GPT and ElevenLabs to join your online meetings, listen for your name and answers questions with your voice
- [RealChar](https://github.com/Shaunwei/RealChar) Create, Customize and Talk to your AI Character/Companion in Realtime using GPT3.5/4, Claude2, Chroma Vector DB, Whisper Speech2Text, ElevenLabs Text2Speech
- [gdansk-ai](https://github.com/jmaczan/gdansk-ai) full stack AI voice chatbot (speech-to-text, LLM, text-to-speech) with integrations to Auth0, OpenAI, Google Cloud API and Stripe - Web App, API
- [bark TTS for oobabooga/text-generation-webui](https://github.com/wsippel/bark_tts) make your local LLM talk
- [bark TTS for oobabooga/text-generation-webui](https://github.com/minemo/text-generation-webui-barktts) another implementation
- [iris-llm](https://github.com/dkjroot/iris-llm/tree/prototypes) local voice chat agent
- [Kobold-Assistant](https://github.com/lee-b/kobold_assistant) Fully conversational local OpenAI Whisper + Local LLMS + Local Coqui
- [WhisperFusion](https://github.com/collabora/WhisperFusion) ultra low latency conversations built with WhisperLive, WhisperSpeech and Mistral
- [Linguflex](https://github.com/KoljaB/Linguflex) voice assistant with smart home devices control, music control, internet search, email manipulation
- [GLaDOS](https://github.com/dnhkng/GlaDOS) project dedicated to building a real-life version of GLaDOS a fictional AI from the game Portal with a quirky personality
- [AlwaysReddy](https://github.com/ILikeAI/AlwaysReddy) LLM voice assistant with TTS, STT, reading/writing to clipboard with OpenAI, Anthropic and Local LLM support
- [LocalAIVoiceChat](https://github.com/KoljaB/LocalAIVoiceChat) Local AI talk with a custom voice based on Zephyr 7B model. Uses RealtimeSTT with faster_whisper for transcription and RealtimeTTS with Coqui XTTS for synthesis

## Retrieval Augmented Generation (RAG)

- [sqlchat](https://github.com/sqlchat/sqlchat) Use OpenAI GPT3/4 to chat with your database
- [chat-with-github-repo](https://github.com/peterw/Chat-with-Github-Repo) which uses streamlit, gpt3.5-turbo and deep lake to answer questions about a git repo
- [mpoon/gpt-repository-loader](https://github.com/mpoon/gpt-repository-loader) uses Git and GPT-4 to convert a repository into a text format for various tasks, such as code review or documentation generation.
- [chat-your-data](https://github.com/hwchase17/chat-your-data) Create a ChatGPT like experience over your custom docs using LangChain
- [embedchain](https://github.com/embedchain/embedchain) python based RAG Framework
- [dataherald](https://github.com/Dataherald/dataherald) a natural language-to-SQL engine built for enterprise-level question answering over structured data. It allows you to set up an API from your database that can answer questions in plain English
- [databerry](https://github.com/gmpetrov/databerry) create proprietary data stores that can be accessed by GPT
- [Llama-lab](https://github.com/run-llama/llama-lab) home of llama_agi and auto_llama using LlamaIndex
- [PrivateGPT](https://github.com/imartinez/privateGPT) a standalone question-answering system using LangChain, GPT4All, LlamaCpp and embeddings models to enable offline querying of documents
- [Spyglass](https://github.com/spyglass-search/spyglass) tests an Alpaca integration for a self-hosted personal search app. Select the llama-rama feature branch. [Discussion on reddit](https://www.reddit.com/r/LocalLLaMA/comments/13key7p/a_little_demo_integration_the_alpaca_model_w_my/)
- [local_llama](https://github.com/jlonge4/local_llama) chatting with your PDFs offline. gpt_chatwithPDF alternative with the ultimate goal of using llama instead of chatGPT
- [Sidekick](https://github.com/ai-sidekick/sidekick) Information retrieval for LLMs
- [DB-GPT](https://github.com/csunny/DB-GPT) SQL generation, private domain Q&A, data processing, unified vector storage/indexing, and support for various plugins and LLMs
- [localGPT](https://github.com/PromtEngineer/localGPT) a privateGPT inspired document question-answering solution using GPU instead of CPU acceleration and InstructorEmbeddings, which perform better [according to leaderboards](https://huggingface.co/spaces/mteb/leaderboard) instead of LlamaEmbeddings
- [LocalDocs](https://docs.gpt4all.io/gpt4all_chat.html#how-localdocs-works) plugin for GPT4All
- [annoy_ltm](https://github.com/YenRaven/annoy_ltm) extension to add long term memory to chatbots using a nearest neighbor vector DB for memory retrieval
- [ChatDocs](https://github.com/marella/chatdocs) PrivateGPT + Web UI + GPU Support + ggml, transformers, webui
- [PAutoBot](https://github.com/nrl-ai/pautobot) document question-answering engine developed with LangChain, GPT4All, LlamaCpp, ChromaDB, PrivateGPT, CPU only
- [AIDE](https://github.com/vsraptor/aide/tree/main) CLI based privateGPT fork, improved, refactored, multiline support, model switch support, non question command support
- [khoj](https://github.com/khoj-ai/khoj) Chat offline with your second brain using Llama 2, supporting multiple data sources, web search etc.
- [secondbrain](https://github.com/juliooa/secondbrain) Multi-platform desktop app to download and run LLMs locally in your computer
- [local-rag](https://github.com/jonfairbanks/local-rag) Ingest files for RAG with open LLMs, without 3rd parties or data leaving your network
- [Paper QA](https://github.com/whitead/paper-qa) LLM Chain for answering questions from documents with citations, using OpenAI Embeddings or local llama.cpp, langchain and FAISS Vector DB
- [BriefGPT](https://github.com/e-johnstonn/BriefGPT) document summarization and querying using OpenAI' and locally run LLM's using LlamaCpp or GPT4ALL, and embeddings stored as a FAISS index, built using Langchain.
- [anything-llm](https://github.com/Mintplex-Labs/anything-llm) document ingestion, supports multiple vector DBs, remote and local LLMs and supports chat and query mode with Chat Web UI, agents, code execution, web browsing, multi user, citations
- [factool](https://github.com/gair-nlp/factool) factuality Detection in Generative AI
- [opencopilot](https://github.com/opencopilotdev/opencopilot) LLM agnostic, open source Microsoft Copilot alternative to easily built copilot functionality with RAG, Knowledgebase, Conversional History, Eval, UX into your product
- [DocsGPT](https://github.com/arc53/DocsGPT) chat with your project documentation using RAG, supports OpenAI and local LLMs, and also provides a RAG-fine-tuned docsgpt-14b [model](https://huggingface.co/Arc53/docsgpt-14b)
- [Swiss Army Llama](https://github.com/Dicklesworthstone/swiss_army_llama) FastAPI service for semantic text search using precomputed embeddings and advanced similarity measures, with built-in support for various file types through textract
- [Quivr](https://github.com/StanGirard/quivr) Dump all your files and thoughts into your private GenerativeAI Second Brain and chat with it
- [danswer](https://github.com/danswer-ai/danswer) Model agnostic RAG QA with many advanced features like Hybrid search + Reranking, time extraction, user intent identification, User access level management, document update and connectors for many SaaS tools
- [SecureAI-Tools](https://github.com/SecureAI-Tools/SecureAI-Tools) Chat with local documents through various local or commercial models, supporting user authentication
- [OpenCopilot](https://github.com/openchatai/OpenCopilot) implement RAG principles with your own LLM supporting API calling of multiple endpoints
- [RAGatouille](https://github.com/bclavie/RAGatouille) Retrievel with ColBERT and other implementations of SOTA research for your RAG pipeline 
- [QAnything](https://github.com/netease-youdao/QAnything) two stage retrieval based on retrieve-and-rerank approach with SOTA performance for EN/CN and planned support for structured and unstructured data and DBs
- [opengpts](https://github.com/langchain-ai/opengpts) open source GPTs and Assistants with LangChain, LangServe and LangSmith. LLM agnostic, Prompt Engineering, Tool support, Vector DB agnostic, Various Retrieval Algorithms, Chat History support
- [cognee](https://github.com/topoteretes/cognee) Memory management for RAG and AI Applications and Agents
- [bionic-gpt](https://github.com/bionic-gpt/bionic-gpt) LLM deployment with authentication, team and RBAC functionality, RAG pipeline, tenants etc.
- [rawdog](https://github.com/AbanteAI/rawdog) CLI assistant that responds by generating and auto-executing a Python script. Recursive Augmentation With Deterministic Output Generations (RAWDOG) is a novel alternative to RAG
- [ADeus](https://github.com/adamcohenhillel/ADeus) RAG Chatbot for everything you say, by using an always on audio recorder and a Web App
- [llm-answer-engine](https://github.com/developersdigest/llm-answer-engine) a Perplexity-Inspired Answer Engine Using Next.js, Groq, Mixtral, Langchain, OpenAI, Brave & Serper
- [R2R](https://github.com/SciPhi-AI/R2R) open-source framework for building, deploying and optimizing enterprise RAG systems using FastAPI, LiteLLM, DeepEval and flexible components
- [RAGFlow](https://github.com/infiniflow/ragflow) open-source RAG engine with two step retrieaval and re-ranking and deepdoc vision document parsing, supporting [RAPTOR](https://arxiv.org/html/2401.18059v1), FlagEmbeddings BCE and BGE rerankers
- [FreeAskInternet](https://github.com/nashsu/FreeAskInternet) Perplexity inspired, private and local search aggregator using LLMs
- [dify](https://github.com/langgenius/dify) open-source LLM RAG development with visual graph based workflow editor, observability and model management
- [morphic](https://github.com/miurla/morphic) slick RAG / Perplexity inspired stack built on next.js and tailwind
- [jina-reader](https://github.com/jina-ai/reader) web app that scrapes/crawsl and parses websites then converts the content to an LLM-friendly input to use in RAG and Tool/Agent workflows
- [supermemory](https://github.com/Dhravya/supermemory) second brain with memory for your browser bookmarks and tweets
- [storm](https://github.com/stanford-oval/storm) Stanford created LLM-powered knowledge curation system that researches a topic and generates a full-length reports with citations from the web
- [Firecrawl](https://github.com/mendableai/firecrawl) scrapes/crawls and parses websites and turns them into LLM-ready markdown
- [llm-scraper](https://github.com/mishushakov/llm-scraper) scrape and turn any webpage into structured data using LLMs
- [reor](https://github.com/reorproject/reor) LLM assisted note taking with RAG capabilities
- [cognita](https://github.com/truefoundry/cognita) LangChain & LlamaIndex Wrapper organizing all RAG components in a modular, API driven and extensible way
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) AI-powered search engine alternative to Perplexity AI 
- [scrapegraph-ai](https://github.com/VinciGit00/Scrapegraph-ai) web scraper for python using llm and graph logic to create scraping pipelines
- [griptape](https://github.com/griptape-ai/griptape) a modular Python framework for building AI-powered applications for enterprise data and APIs. Agents, Pipelines, Workflows, Tools, Memory
- [adaptive-rag](https://pathway.com/developers/showcases/adaptive-rag) cut LLM costs without sacrificing accuracy by dynamically change the number of docs
- [AFFiNE](https://github.com/toeverything/AFFiNE) knowledge base as a Notion, Miro and Airtable alternative with multimodal AI generation
- [data-to-paper](https://github.com/Technion-Kishony-lab/data-to-paper) AI driven research from data with human-verifiability
- [ragapp](https://github.com/ragapp/ragapp) Easy Agentic RAG for Enterprise based on LlamaIndex
- [Argilla](https://github.com/argilla-io/argilla) human expert rating platform to improve AI output quality based to be used for RLHF and other techniques
- [Mem0](https://github.com/mem0ai/mem0) provides a smart, self-improving memory layer for LLMs, enabling adaptive personalization by retaining user, session, and AI agent memories using a developer-friendly API
- [FlashRank](https://github.com/PrithivirajDamodaran/FlashRank) allows users to add ultra-light and super-fast re-ranking capabilities to existing search and retrieval pipelines using SoTA LLMs and cross-encoders without needing Torch or Transformers, making it highly efficient for CPU usage and cost-effective for serverless deployments [RAG with Query Expansion, Colbert v2 & FlashRank](https://aksdesai1998.medium.com/improving-rag-with-query-expansion-reranking-models-31d252856580)
- [GraphRAG](https://github.com/microsoft/graphrag) enhance LLM outputs by utilizing knowledge graph memory structures, leveraging Azure resources for structured data extraction from unstructured text.
- [GraphRAG-Local-UI](https://github.com/severian42/GraphRAG-Local-UI) UI for GraphRAG supporting local LLMs with an interactive Gradio-based UI, offering real-time graph visualization and flexible querying without reliance on cloud models.
- [vanna](https://github.com/vanna-ai/vanna) generates vector embeddings of your DB schema, documentation and example queries in order to do generate matching Queries based on a user input for RAG
- [indexify](https://github.com/tensorlakeai/indexify) building fast data pipelines for unstructured data (video, audio, images and documents) using extractors for embedding, transformation and feature extraction allowing real time and incremental extraction for RAG workflows
- [MindSearch](https://github.com/InternLM/MindSearch) AI Search Engine and question answering framework with Perplexity.ai Pro performance using a graph based detailed solution path (multi turn), web search, providing a sleek Web UI
- [llm-graph-builder](https://github.com/neo4j-labs/llm-graph-builder) turning unstructured data from pdfs, docs, txt, videos, websites into a knowledge graph in neo4j using LLMs to extract entities, nodes, relationships and properties. Built on Langchain.

## Browser Extensions

- [sider](https://chrome.google.com/webstore/detail/sider-chatgpt-sidebar-gpt/difoiogjjojoaoomphldepapgpbgkhkb) chrome side-bar for chatGPT and OpenAI API supporting custom prompts and text highlighting
- [chathub-dev/chathub](https://github.com/chathub-dev/chathub)
- [Glarity](https://github.com/sparticleinc/chatgpt-google-summary-extension) open-source chrome extension to write summaries for various websites including custom ones and YouTube videos. Extensible
- [superpower-chatgpt](https://github.com/saeedezzati/superpower-chatgpt) chrome extension / firefox addon to add missing features like Folders, Search, and Community Prompts to ChatGPT
- [Lumos](https://github.com/andrewnguonly/Lumos) Chrome Extension with OLlama Backend as a RAG LLM co-pilot for browsing the web
- [chatGPTBox](https://github.com/josStorer/chatGPTBox) add useful LLM chat-boxes to github and other websites, supporting self-hosted model (RWKV, llama.cpp, ChatGLM)

## Agents / Automatic GPT

- [Auto GPT](https://github.com/Torantulino/Auto-GPT)
- [AgentGPT](https://github.com/reworkd/AgentGPT) Deploy autonomous AI agents, using vectorDB memory, web browsing via LangChain, website interaction and more including a GUI
- [microGPT ](https://github.com/muellerberndt/micro-gpt) Autonomous GPT-3.5/4 agent, can analyze stocks, create art, order pizza, and perform network security tests
- [Auto GPT Plugins](https://github.com/Significant-Gravitas/Auto-GPT-Plugins)
- [AutoGPT-Next-Web](https://github.com/Dogtiti/AutoGPT-Next-Web) An AgentGPT fork as a Web GUI
- [AutoGPT Web](https://github.com/jina-ai/auto-gpt-web)
- [AutoGPT.js](https://github.com/zabirauf/AutoGPT.js)
- [LoopGPT](https://github.com/farizrahman4u/loopgpt) a re-implementation of AutoGPT as a proper python package, modular and extensible
- [Camel-AutoGPT](https://github.com/SamurAIGPT/Camel-AutoGPT) Communicaton between Agents like BabyAGI and AutoGPT
- [BabyAGIChatGPT](https://github.com/Doriandarko/BabyAGIChatGPT) is a fork of BabyAGI to work with OpenAI's GPT, pinecone and google search
- [GPT Assistant](https://github.com/BuilderIO/gpt-assistant) An autonomous agent that can access and control a chrome browser via Puppeteer 
- [gptchat](https://github.com/ian-kent/gptchat) a client which uses GPT-4, adding long term memory, can write its own plugins and can fulfill tasks
- [Chrome-GPT](https://github.com/richardyc/Chrome-GPT) AutoGPT agent employing Langchain and Selenium to interact with a Chrome browser session, enabling Google search, webpage description, element interaction, and form input
- [autolang](https://github.com/alvarosevilla95/autolang) Another take on BabyAGI, focused on workflows that complete. Powered by langchain.
- [ai-legion](https://github.com/eumemic/ai-legion) A framework for autonomous agents who can work together to accomplish tasks.
- [generativeAgent_LLM](https://github.com/QuangBK/generativeAgent_LLM) Generative Agents with Guidance, Langchain, and local LLMs, implementation of the "Generative Agents: Interactive Simulacra of Human Behavior" [paper](https://arxiv.org/pdf/2304.03442.pdf), [blogpost](https://betterprogramming.pub/implement-generative-agent-with-local-llm-guidance-and-langchain-full-features-fa57655f3de1)
- [gpt-engineer](https://github.com/AntonOsika/gpt-engineer) generates a customizable codebase based on prompts using GPT4, and is easy to adapt and extend; runs on any hardware that can run Python.
- [gpt-migrate](https://github.com/0xpayne/gpt-migrate) takes your existing code base and migrates to another framework or language
- [MetaGPT](https://github.com/geekan/MetaGPT) multi agent meta programming framework. takes requirements as input and outputs user stories, analysis, data structures, etc. MetaGPT includes product managers, architects, PMs, engineers and uses SOPs to run, [paper](https://arxiv.org/abs/2308.00352v4)
- [aider](https://github.com/paul-gauthier/aider) command-line chat tool that allows you to write and edit code with OpenAI's GPT models
- [AutoChain](https://github.com/Forethought-Technologies/AutoChain) Build lightweight, extensible, and testable LLM Agents
- [chatdev](https://github.com/openbmb/chatdev) Develop Custom Software using Natural Language, while an LLM-powered Multi-Agent Team develops the software for you, [paper](https://arxiv.org/pdf/2307.07924v3.pdf)
- [AutoAgents](https://github.com/Link-AGI/AutoAgents) Generate different roles for GPTs to form a collaborative entity for complex tasks, [paper](https://arxiv.org/abs/2309.17288v2)
- [RestGPT](https://github.com/Yifan-Song793/RestGPT) LLM-based autonomous agent controlling real-world applications via RESTful APIs
- [MemGPT](https://github.com/cpacker/MemGPT) intelligently manages different memory tiers in LLMs to provide extended context, supporting vector DBs, SQL, Documents etc
- [XAgent](https://github.com/OpenBMB/XAgent) Autonomous LLM Agent for Complex Task Solving
- [HAAS](https://github.com/daveshap/OpenAI_Agent_Swarm) Hierarchical Autonomous Agent Swarm create a self-organizing and ethically governed ecosystem of AI agents, inspired by ACE Framework
- [agency-swarm](https://github.com/VRSEN/agency-swarm) agent orchestration framework enabling the creation of a collaborative swarm of agents (Agencies), each with distinct roles and capabilities
- [Auto Vicuna Butler](https://github.com/NiaSchim/auto-vicuna-butler) Baby-AGI fork / AutoGPT alternative to run with local LLMs
- [BabyAGI](https://github.com/yoheinakajima/babyagi) AI-Powered Task Management for OpenAI + Pinecone or Llama.cpp
- [Agent-LLM](https://github.com/Josh-XT/Agent-LLM) Webapp to control an agent-based Auto-GPT alternative, supporting GPT4, Kobold, llama.cpp, FastChat, Bard, Oobabooga textgen
- [auto-llama-cpp](https://github.com/rhohndorf/Auto-Llama-cpp) fork of Auto-GPT with added support for locally running llama models through llama.cpp
- [AgentOoba](https://github.com/flurb18/AgentOoba) autonomous AI agent extension for Oobabooga's web ui
- [RecurrentGPT](https://github.com/aiwaves-cn/RecurrentGPT/tree/main) Interactive Generation of (Arbitrarily) Long Text. Uses LSTM, prompt-engineered recurrence, maintains short and long-term memories, and updates these using semantic search and paragraph generation.
- [SuperAGI](https://github.com/TransformerOptimus/SuperAGI) open-source framework that enables developers to build, manage, and run autonomous agents. Supports tools extensions, concurrent agents, GUI, console, vector DBs, multi modal, telemetry and long term memory
- [GPT-Pilot](https://github.com/Pythagora-io/gpt-pilot) writes scalable apps from scratch while the developer oversees the implementation
- [DevOpsGPT](https://github.com/kuafuai/DevOpsGPT) Multi agent system for AI-driven software development. Combine LLM with DevOps tools to convert natural language requirements into working software
- [ToRA](https://github.com/microsoft/ToRA) Tool-integrated Reasoning Agents designed to solve challenging mathematical reasoning problems by interacting with tools, e.g., computation libraries and symbolic solvers, [paper](https://arxiv.org/abs/2309.17452)
- [ACE](https://github.com/daveshap/ACE_Framework) Autonomous Cognitive Entities Framework to automatically create autonomous agents and sub agents depending on the tasks at hand
- [SuperAgent](https://github.com/homanp/superagent) Build, deploy, and manage LLM-powered agents
- [aiwaves-cn/agents](https://github.com/aiwaves-cn/agents) Open-source Framework for Autonomous Language Agents with LSTM, Tool Usage, Web Navigation, Multi Agent Communication and Human-Agent interaction, [paper](https://arxiv.org/pdf/2309.07870.pdf)
- [autogen](https://github.com/microsoft/autogen) framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks, [paper](https://arxiv.org/abs/2308.08155v2)
- [openagents](https://github.com/xlang-ai/openagents) an Open Platform for Language Agents in the Wild, [paper](https://arxiv.org/abs/2310.10634)
- [TaskWeaver](https://github.com/microsoft/TaskWeaver) code-first agent framework for planning and executing data analytics tasks interpreting user requests and coordinating plugins
- [crewAI](https://github.com/joaomdmoura/crewAI) framework for orchestrating role-playing, autonomous AI agents
- [phidata](https://github.com/phidatahq/phidata) toolkit for building AI Assistants using function calling enabling RAG and other workflows
- [FRIDAY](https://github.com/OS-Copilot/FRIDAY) Framework for Computer Agents with Self-Improvement on OSX and Linux
- [agentkit](https://github.com/BCG-X-Official/agentkit) Starter-kit to build constrained agents with Nextjs, FastAPI and Langchain
- [LaVague](https://github.com/lavague-ai/LaVague) control a web browser through natural language instructions using visual language models, a Large Action Model framework for AI Web Agents
- [Skyvern](https://github.com/Skyvern-AI/skyvern) control a web browser through natural language instructions using visual language models
- [AIOS](https://github.com/agiresearch/AIOS) SDK that embeds large language model into Operating Systems providing Agent workflows, OS Kernel integration and System Calls via LLM Kernel (Agent, Context, Memory, Storage, Tools, Access)
- [WebLlama](https://github.com/McGill-NLP/webllama) code and [Llama-3-8B-web](https://huggingface.co/McGill-NLP/Llama-3-8B-Web) model to build agents that browse the web by following chat style instructions
- [memary](https://github.com/kingjulio8238/memary) Longterm Memory for Autonomous Agents with Routing Agent (ReAct) Knowledge Graph creation and retrieval with Neo4j, Memory Stream and Entity Knowledge Store
- [maestro](https://github.com/Doriandarko/maestro) Subagent orchestration that breaks down tasks into subtasks and orchestrates its execution and allows for refinement supporting Claude, Groq, GPT-4o and local Ollama/LMStudio
- [AutoGroq](https://github.com/jgravelle/AutoGroq) Create AutoGen compatible teams with assistants and workflows from a simple text prompt
- [FinRobot](https://github.com/AI4Finance-Foundation/FinRobot) AI Agent Platform for Financial Applications using LLMs
- [llama-fs](https://github.com/iyaja/llama-fs) organizes a folder and renames files on your system by looking at each file and creating a useful structure based on metadata and common conventions
- [Leon](https://github.com/leon-ai/leon) personal assistant with multiple features like TTS, ASR, LLM usage
- [Vision Agent](https://github.com/landing-ai/vision-agent) allows users to describe vision problems in text and utilizes agent frameworks to generate code solutions, leveraging existing vision models to expedite task completion.
- [Lagent](https://github.com/InternLM/lagent) allows users to efficiently build LLM-based agents with a unified interfacing design, supporting various models and customizable actions using frameworks like OpenAI API, Transformers, and LMDeploy
- [IoA](https://github.com/OpenBMB/IoA) a framework where diverse AI agents, using an internet-inspired architecture, can autonomously form teams and execute tasks asynchronously, leveraging heterogeneous agent integration and adaptive conversation flows
- [Atomic Agents](https://github.com/KennyVaneetvelde/atomic_agents) a framework designed to be modular, extensible, and easy to use to build agents on top of Instructor and Pydantic

## Multi Modal

- [huggingGPT / JARVIS](https://github.com/microsoft/JARVIS) Connects LLMs with huggingface specialized models
- [Langchain-huggingGPT](https://github.com/camille-vanhoffelen/langchain-huggingGPT) reimplementation of HuggingGPT using langchain
- [OpenAGI](https://github.com/agiresearch/openagi) AGI research platform, solves multi step tasks with RLTF and supports complex model chains
- [ViperGPT](https://github.com/cvlab-columbia/viper) implementation for visual inference and reasoning with openAPI
- [TaskMatrix](https://github.com/microsoft/visual-chatgpt) former visual-chatgpt connects ChatGPT and a series of Visual Foundation Models to enable sending and receiving images during chatting.
- [PandaGPT](https://github.com/yxuansu/PandaGPT) combines ImageBind and Vicuna to understand and combine multimodal inputs from text, image, audio, depth, thermal, and IMU.
- [AGiXT](https://github.com/Josh-XT/AGiXT) agents with memory, model agnostic, docker deployment, plugin extendable, chat feature, speech to text and text to speech, REST api and more
- [SelfTalker](https://github.com/Amirrezahmi/SelfTalker) Talk with your virtual self using voice cloning, LLMs and computer vision models
- [CoDi](https://github.com/microsoft/i-Code/tree/main/i-Code-V3) Any to any generation via composable diffusion
- [AutoMix](https://github.com/automix-llm/automix) Mixing Language Models with Self-Verification and Meta-Verification, [paper](https://arxiv.org/abs/2310.12963v1)
- [NExT-GPT](https://github.com/NExT-GPT/NExT-GPT) Any-to-Any Multimodal LLM for arbitary input-output combinations (any-to-any) for text, image, video, audio and beyond, [paper](https://arxiv.org/pdf/2309.05519), [weights](https://huggingface.co/ChocoWu/nextgpt_7b_tiva_v0)
- [SpeechGPT](https://github.com/0nutation/SpeechGPT) Empowering LLMs with Intrinsic Cross-Modal Conversational Abilities for speech audio input and output
- [OpenFLamingo-v2](https://github.com/mlfoundations/open_flamingo) MPT and RedPajama fine tuned on the OpenFLamingo data set for training Autoregressive Vision-Language Models, [models](https://huggingface.co/openflamingo)
- [Obsidian](https://huggingface.co/NousResearch/Obsidian-3B-V0.5) 3B open source multimodal visual LLM
- [ml-ferret](https://github.com/apple/ml-ferret) Refer and Ground Anything Anywhere at Any Granularity
- [CogVLM](https://github.com/thudm/cogvlm) SOTA open visual language model and Agent
- [Video-LLaVA](https://github.com/PKU-YuanGroup/Video-LLaVA) Image and Video dense LLM and [MoE-LLaVA](https://github.com/PKU-YuanGroup/MoE-LLaVA) 3B sparse Mixture of Expert model outperforming the original dense 7B model
- [MobileAgent](https://github.com/X-PLUG/MobileAgent) Autonomous Multi-Modal Mobile Device Agent with Visual Perception that can execute tasks
- [MiniCPM-V](https://github.com/OpenBMB/MiniCPM-V) MiniCPM-V and OmniLMM multimodal vision & language models with OCR and text-vision reasoning capabilities
- [AppAgent](https://github.com/mnotgod96/AppAgent) Multimodal Agents as Smartphone Users
- [InternVL](https://github.com/OpenGVLab/InternVL) InternVL-Chat Model and surrounding technology to rebuild a Visual Language Model
- [PyWinAssistant](https://github.com/a-real-ai/pywinassistant) Large Action Model for Windows 10/11 win32api controlling User Interfaces via Visualization-of-Thought (VoT)
- [Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) a lightweight, state-of-the-art open multimodal model built upon datasets which include - synthetic data and filtered publicly available websites
- [llama3v](https://huggingface.co/mustafaaljadery/llama3v) vision model that is powered by Llama3 8B and siglip-so400m matching gpt4-v on some benchmarks
- [Zerox OCR](https://github.com/getomni-ai/zerox) allows users to convert PDFs into Markdown using a vision-based OCR process with GPT-4o-mini, optimizing for complex layouts like tables and charts

## Code generation

- [FauxPilot](https://github.com/fauxpilot/fauxpilot) open source Copilot alternative using Triton Inference Server
- [Turbopilot](https://github.com/ravenscroftj/turbopilot) open source LLM code completion engine and Copilot alternative
- [Tabby](https://github.com/TabbyML/tabby) Self hosted Github Copilot alternative with RAG-based code completion which utilizes repo-level context
- [starcoder.cpp](https://github.com/bigcode-project/starcoder.cpp)
- [GPTQ-for-SantaCoder](https://github.com/mayank31398/GPTQ-for-SantaCoder) 4bit quantization for SantaCoder
- [supercharger](https://github.com/catid/supercharger) Write Software + unit tests for you, based on Baize-30B 8bit, using model parallelism
- [Autodoc](https://github.com/context-labs/autodoc) toolkit that auto-generates codebase documentation using GPT-4 or Alpaca, and can be installed in a git repository in about 5 minutes.
- [smol-ai developer](https://github.com/smol-ai/developer) a personal junior developer that scaffolds an entire codebase with a human-centric and coherent whole program synthesis approach using \<200 lines of Python and Prompts.
- [locai](https://github.com/Maykeye/locai) kobold/oobabooga -compatible api for vscode
- [oasis](https://github.com/paolorechia/oasis) local LLaMA models in VSCode
- [aider](https://github.com/paul-gauthier/aider) cli tool for writing and modifying code with GPT-3.5 and GPT-4
- [continue](https://github.com/continuedev/continue) open-source copilot alternative for software development as a VS Code plugin, can use gpt-4 API or local codellama and other models
- [chatgpt-vscode](https://github.com/mpociot/chatgpt-vscode) vscode extension to use unofficial chatGPT API for a code context based chat side bar within the editor
- [codeshell-vscode](https://github.com/WisdomShell/codeshell-vscode) vscode extension to use the CodeShell-7b models
- [localpilot](https://github.com/danielgross/localpilot) vscode copilot alternative using local llama.cpp/ggml models on Mac
- [sweep](https://github.com/sweepai/sweep) AI-powered Junior Developer for small features and bug fixes.
- [devika](https://github.com/stitionai/devika) Open Source Devin clone. Software Engineer that takes high level human instructions, breaks them down, plans ahead and creates a software product out of it
- [OpenDevin](https://github.com/OpenDevin/OpenDevin) Open Source Devin clone imitating an autonomous AI software engineer who is capable of executing complex engineering tasks and collaborating actively with users on software development projects
- [OpenCodeInterpreter](https://github.com/OpenCodeInterpreter/OpenCodeInterpreter) Interface, framework and models for code generation, execution and improvement
- [gptscript](https://github.com/gptscript-ai/gptscript) natural language scripting language to achieve tasks by writing and executing code using an LLM
- [tlm](https://github.com/yusufcanb/tlm) Local CLI Copilot, powered by CodeLLaMa
- [llm-cmd](https://github.com/simonw/llm-cmd) Use LLM to generate and execute commands in your terminal/shell/cli
- [gorilla-cli](https://github.com/gorilla-llm/gorilla-cli) use natural language in the terminal to assist with command writing, gorilla writes the commands based on a user prompt, while the user just approves them
- [SWE-agent](https://github.com/princeton-nlp/SWE-agent) system for autonomously solving issues in GitHub repos. Gets similar accuracy to Devin on SWE-bench, takes 93 seconds on avg
- [openui](https://github.com/wandb/openui) v0.dev alternative for text guided UI creation for HTML/React,Svelte, Web Components, etc.
- [codel](https://github.com/semanser/codel) autonomus agent performing tasks and projects using terminal, browser and editor
- [AutoCodeRover](https://github.com/nus-apr/auto-code-rover) automated GitHub issue resolver for bug fixes and feature addition
- [plandex](https://github.com/plandex-ai/plandex) terminal-based AI coding agent for complex tasks with planning and execution capabilities
- [AutoCoder](https://github.com/bin123apple/AutoCoder) Agentic code generation, execution and verification allowing external packages and using a fine tuned deepseeker-coder model AutoCoder-33B and 6.7B model
- [Amplication](https://github.com/amplication/amplication) allows users to automate backend application development for .NET and Node.js using an AI-powered platform, ensuring scalable and secure code with a user-friendly, plugin-based architecture.
- [twinny](https://github.com/twinnydotdev/twinny) VS Code Extension for Github Copilot like code completion and chat assistance, leveraging customizable API endpoints and supporting multiple backends like Ollama and llama.cpp
- [Mutahunter](https://github.com/codeintegrity-ai/mutahunter) generate unit tests automatically and perform LLM-based mutation testing, enhancing fault detection with context-aware mutations across various programming languages

## Libraries and Wrappers

- [acheong08/ChatGPT Python](https://github.com/acheong08/ChatGPT) reverse engineerded chatGPT API
- [gpt4free](https://github.com/xtekky/gpt4free) Use reverse engineered GPT3.5/4 APIs of other website's APIs
- [GPTCache](https://github.com/zilliztech/GPTCache), serve cached results based on embeddings in a vector DB, before querying the OpenAI API.
- [kitt](https://github.com/livekit-examples/kitt) TTS + GPT4 + STT to create a conference call audio bot
- [Marvin](https://github.com/prefecthq/marvin) simplifies AI integration in software development with easy creation of AI functions and bots managed through a conversational interface
- [chatgpt.js](https://github.com/chatgptjs/chatgpt.js) client-side JavaScript library for ChatGPT
- [ChatGPT-Bridge](https://github.com/improveTheWorld/ChatGPT-Bridge) use chatGPT plus' GPT-4 as a local API
- [Powerpointer](https://github.com/CyberTimon/powerpointer) connects to openAPI GPT3.5 and creates a powerpoint out of your content
- [EdgeGPT](https://github.com/acheong08/EdgeGPT) Reverse engineered API of Microsoft's Bing Chat using Edge browser
- [simpleaichat](https://github.com/minimaxir/simpleaichat) python package for simple and easy interfacing with chat AI APIs
- [Dotnet SDK for openai](https://github.com/betalgo/openai) chatGPT, Whisper, GPT-4 and Dall-E SDK for .NET
- [node-llama-cpp](https://github.com/withcatai/node-llama-cpp) TS library to locally run many models supported by llama.cpp, enhanced with many convenient features, like forcing a JSON schema on the model output on the generation level
- [FastLLaMA Python wrapper for llama.cpp](https://github.com/PotatoSpudowski/fastLLaMa)
- [WebGPT](https://github.com/0hq/WebGPT) Inference in pure javascript
- [TokenHawk](https://github.com/kayvr/token-hawk) performs hand-written LLaMA inference using WebGPU, utilizing th.cpp, th-llama.cpp, and th-llama-loader.cpp, with minimal dependencies
- [WasmGPT](https://github.com/lxe/ggml/tree/wasm-demo) ChatGPT-like chatbot in browser using ggml and emscripten
- [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) easy-to-use model GPTQ quantization package with user-friendly CLI
- [gpt-llama.cpp](https://github.com/keldenl/gpt-llama.cpp) Replace OpenAi's GPT APIs with llama.cpp's supported models locally
- [llama-node](https://github.com/Atome-FE/llama-node) JS client library for llama (or llama based) LLMs built on top of llama-rs and llama.cpp.
- [TALIS](https://github.com/Dhaladom/TALIS) serves a LLaMA-65b API, optimized for speed utilizing dual RTX 3090/4090 GPUs on Linux
- [Powerpointer-For-Local-LLMs](https://github.com/CyberTimon/Powerpointer-For-Local-LLMs) connects to oobabooga's API and creates a powerpoint out of your content
- [OpenChatKit](https://github.com/togethercomputer/OpenChatKit) open-source project that provides a base to create both specialized and general purpose chatbots and extensible retrieval system, using GPT-NeoXT-Chat-Base-20B as a base model
- [webgpu-torch](https://github.com/praeclarum/webgpu-torch) Tensor computation with WebGPU acceleration
- [llama-api-server](https://github.com/iaalm/llama-api-server) that uses llama.cpp and emulates an openAI API
- [CTransformers](https://github.com/marella/ctransformers) python bindings for transformer models in C/C++ using GGML library, supporting GPT-2/J/NeoX, StableLM, LLaMA, MPT, Dollyv2, StarCoder
- [basaran](https://github.com/hyperonym/basaran) GUI and API as a drop-in replacement of the OpenAI text completion API. Broad HF eco system support (not only llama)
- [CodeTF](https://github.com/salesforce/CodeTF) one-stop Python transformer-based library for code LLMs and code intelligence, training and inferencing on code summarization, translation, code generation
- [CTranslate2](https://github.com/OpenNMT/CTranslate2) provides fast Transformer (llama, falcon and more) inference for CPU and GPU, featuring compression, parallel execution, framework support
- [auto-gptq](https://github.com/PanQiWei/AutoGPTQ) easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ for GPU inference
- [exllama](https://github.com/turboderp/exllama) Memory-Efficient Llama Rewrite in Python/C++/CUDA for 4bit quantized GPTQ weights, running on GPU, faster than llama.cpp ([2023-06-13](https://www.reddit.com/r/LocalLLaMA/comments/147z6as/llamacpp_just_got_full_cuda_acceleration_and_now/)), autoGPTQ and GPTQ-for-llama
- [SimpleAI](https://github.com/lhenault/SimpleAI) Self-Hosted Alternative to openAI API
- [rustformer llm](https://github.com/rustformers/llm) Rust-based ecosystem for llms like BLOOM, GPT-2/J/NeoX, LLaMA and MPT offering a CLI for easy interaction and powered by ggml
- [Haven](https://github.com/havenhq/haven) Fine-Tune and Deploy LLMs On Your Own Infrastructure
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) Python Bindings for llama.cpp with low level C API interface, python API, openai like API and LangChain compatibility
- [candle](https://github.com/huggingface/candle) a minimalist ML framework for Rust with a focus on performance (including GPU support) and ease of use
- [tabbyAPI](https://github.com/theroyallab/tabbyAPI/) OpenAI API emulation using exllamav2 API that's both lightweight and fast
- [LangChain](https://github.com/hwchase17/langchain) Framework for LLM Application Development ([example](https://www.youtube.com/watch?v=iRJ4uab_NIg&t=588s), [paolorechia/learn-langchain with vicuna and GPTQ 4 bit support](https://github.com/paolorechia/learn-langchain))
- [Langstream](https://github.com/rogeriochaves/langstream) a lighter alternative to LangChain
- [LangFlow](https://github.com/logspace-ai/langflow) GUI for Langchain using graphs/flows
- [Toolformer implementation](https://github.com/lucidrains/toolformer-pytorch) Allows LLMs to use Tools
- [megabots](https://github.com/momegas/megabots) to create LLM bots by providing Q&A, document retrieval, vector DBs, FastAPI, Gradio UI, GPTCache, guardrails, whisper, supports OpenAI API (local LLMs planned)
- [gorilla](https://github.com/ShishirPatil/gorilla) Enables LLMs to use tools by semantically and syntactically correctly invoking APIs. Reduces hallucination, custom trained model [weights](https://huggingface.co/TheBloke/gorilla-7B-fp16) based on llama-7b
- [agency](https://github.com/operand/agency) A fast and minimal actor model framework allows humans, AIs, and other computing systems to communicate with each other through shared environments called "spaces".
- [Vercel AI SDK](https://github.com/vercel-labs/ai) a library for building edge-ready AI-powered streaming text and chat UIs in React, Svelte and Vue supporting LangChain, OpenAI, Anthropic and HF
- [tinygrad](https://github.com/geohot/tinygrad) Geohot's implementation for a PyTorch killer with the target to be 2x faster
- [Xorbits Inference (Xinference)](https://github.com/xorbitsai/inference) versatile library designed to deploy and serve language, speech recognition, and multimodal models
- [data-juicer](https://github.com/alibaba/data-juicer) zero code, low code and off the shelf data processing for LLMs
- [Microsoft semantic-kernel](https://github.com/microsoft/semantic-kernel) a lightweight SDK enabling integration of AI Large Language Models (LLMs) with conventional programming languages
- [LlamaIndex](https://github.com/jerryjliu/llama_index) provides a central interface to connect your LLM's with external data
- [haystack](https://github.com/deepset-ai/haystack) LLM orchestration framework to connect models, vector DBs, file converters to pipelines or agents that can interact with your data to build RAG, Q&A, semantic search or conversational agent chatbots
- [rivet](https://github.com/Ironclad/rivet) Visual graph/flow/node based IDE for creating AI agents and prompt chaining for your applications
- [promptflow](https://github.com/microsoft/promptflow) visual graph/flow/node based IDE for creating AI agents
- [Flowise](https://github.com/FlowiseAI/Flowise) Drag & drop UI with visual graph/flow/nodes to build your customized LLM app
- [ChainForge](https://github.com/ianarawjo/ChainForge) visual graph/flow/node based prompt engineering UI for analyzing and evaluating LLM responses
- [LangStream](https://github.com/LangStream/langstream) Event-Driven Developer Platform for Building and Running LLM AI Apps, also providing a visual graph/flow/node based UI. Powered by Kubernetes and Kafka
- [activepieces](https://github.com/activepieces/activepieces) Automation with SaaS tools and GPT using a visual graph/flow/node based workflow
- [kernel-memory](https://github.com/microsoft/kernel-memory) Index and query any data using LLM and natural language, tracking sources and showing citations, ideal for RAG pipelines
- [LocalAI](https://github.com/mudler/LocalAI) Drop-in OpenAI API replacement with local LLMs, Audio To Text (whisper), Image generation (Stable Diffusion), OpenAI functions and Embeddings with single exe deployment
- [dify](https://github.com/langgenius/dify) LLM app development platform combines AI workflow, RAG pipeline, agent capabilities, model management, observability in a visual graph/flow/node editor
- [CopilotKit](https://github.com/CopilotKit/CopilotKit) build fully custom AI Copilots with support for chat, textbox assist, agents and context built on LangChain
- [Bisheng](https://github.com/dataelement/bisheng/blob/main/README_ENG.md) LLM Application Develoment environment mainlzyin Chinese with some English documents
- [Typebot](https://github.com/baptisteArno/typebot.io) allows users to visually create advanced chatbots that can be embedded in web/mobile apps, featuring customizable themes, real-time analytics, and various integration options with services like OpenAI, Google Sheets, and Zapier.
- [DOM to Semantic Markdown](https://github.com/romansky/dom-to-semantic-markdown) convert HTML DOM to semantic Markdown, preserving the semantic structure and metadata for efficient LLM processing, using HTML-to-Markdown AST conversion and customizable options

### Prompt templating / Grammar

- [Jsonformer](https://github.com/1rgs/jsonformer) Generate Structured JSON from Language Models by handling JSON synthax, and letting LLM just output the values
- [Microsoft guidance](https://github.com/microsoft/guidance) templating / grammar for LLMs, [Demo project](https://github.com/paolorechia/local-guidance) by paolorechia for local text-generation-webui. [reddit thread](https://www.reddit.com/r/LocalLLaMA/comments/13kzubz/i_made_a_simple_agent_demo_with_guidance_and/). [guidance fork](https://github.com/Maximilian-Winter/guidance) and [llama-cpp-python fork](https://github.com/Maximilian-Winter/llama-cpp-python) how-to on [reddit](https://www.reddit.com/r/LocalLLaMA/comments/13magac/hi_community_i_created_a_fork_of_microsofts/)
- [outlines](https://github.com/outlines-dev/outlines) Guidance alternative templating / grammar for LLM generation to follow JSON Schemas, RegEx, Caching supporting multiple models, model APIs, and HF transformers
- [lmql](https://github.com/eth-sri/lmql) LMQL templating / grammar language for LLMs based on a superset of Python going beyond constrain-based templating
- [TypeChat](https://github.com/microsoft/TypeChat) templating / grammar for LLMs to enforce constraints for text generation
- [GBNF](https://github.com/ggerganov/llama.cpp/tree/master/grammars) templating / grammar implementation using Bakus-Naur Form (BNF) in llama.cpp to guide output, [BNF Playground](https://bnfplayground.pauliankline.com/)
- [sglang](https://github.com/sgl-project/sglang) structured generation language designed for LLMs with multiple chained generation calls, advanced prompting techniques, control flow, multiple modalities, parallelism, and external interaction
- [DSPy](https://github.com/stanfordnlp/dspy) a framework for algorithmically optimizing LM prompts and weights
- [AlphaCodium](https://github.com/codium-ai/alphacodium) Automatic Code Generation improvements with Prompt Engineering and Flow Engineering
- [aici](https://github.com/microsoft/aici) lets you build Controllers that constrain and direct output of aLLM in real time
- [instructor](https://github.com/jxnl/instructor) structured outputs for LLMs. Pydantic, simple and transparent
- [Every Way To Get Structured Output From LLMs](https://www.boundaryml.com/blog/structured-output-from-llms) explores various methods for obtaining structured output from LLMs, including techniques beyond simple JSON response formatting and regex stacking.
- [AgentInstruct](https://github.com/wang-research-lab/agentinstruct) Instructs Agents to be better at Zero Shot reasoning tasks
- [TextGrad](https://github.com/zou-group/textgrad) optimize coding solutions and problem-solving tasks by implementing automatic differentiation via text feedback from LLMs

## Fine Tuning & Training

- [simple llama finetuner](https://github.com/lxe/simple-llama-finetuner)
- [LLaMA-LoRA Tuner](https://github.com/zetavg/LLaMA-LoRA-Tuner)
- [alpaca-lora](https://github.com/tloen/alpaca-lora)
- [StackLLaMA Fine-Tuning Guide by huggingface](https://huggingface.co/blog/stackllama)
- [xTuring](https://github.com/stochasticai/xturing) LLM finetuning pipeline supporting LoRa & 4bit
- [Microsoft DeepSpeed Chat](https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/README.md)
- [How to train your LLMs](https://blog.replit.com/llm-training)
- [H2O LLM Studio](https://github.com/h2oai/h2o-llmstudio) Framework and no-code GUI for fine tuning SOTA LLMs
- [Implementation of LLaMA-Adapter](https://github.com/ZrrSkywalker/LLaMA-Adapter), to fine tune instructions within hours
- [Hivemind](https://github.com/learning-at-home/hivemind) Training at home
- [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) a llama, pythia, cerebras training environment optimized for Runpod supporting qlora, 4bit, flash attention, xformers
- [LMFlow](https://github.com/OptimalScale/LMFlow) toolbox for finetuning, designed to be user-friendly, speedy, and reliable
- [qlora](https://github.com/artidoro/qlora) uses bitsandbytes quantization and PEFT and transformers for efficient finetuning of quantized LLMs
- [GPTQlora](https://github.com/qwopqwop200/gptqlora) Efficient Finetuning of Quantized LLMs with GPTQ QLoRA and AutoGPTQ for quantization
- [Landmark Attention QLoRA](https://github.com/eugenepentland/landmark-attention-qlora) for landmark attention with 50x context compression and efficient token selection
- [ChatGLM Efficient Finetuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) fine tuning ChatGLM models with PEFT
- [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced) by Huggingface, faster and easier training and deployments of state-of-the-art machine learning models
- [Pearl](https://github.com/facebookresearch/pearl) Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
- [LLaMa2lang](https://github.com/UnderstandLingBV/LLaMa2lang) convenience scripts to finetune any foundation model for chat towards any language
- [fsdp_qlora](https://github.com/AnswerDotAI/fsdp_qlora) Answer.AI's training script enabling 70B training on 48GB vram utilizing QLoRA + FSDP, also available in Axolotl
- [unsloth](https://github.com/unslothai/unsloth) 2-5x faster and 60% less memory local QLoRA finetuning supporting Llama, CodeLlama, Mistral, TinyLlama etc. using Triton
- [transformerlab](https://github.com/transformerlab/transformerlab-app) Download, interact, and finetune models locally in a convenient GUI
- [llm.c](https://github.com/karpathy/llm.c) train GPT and other LLM architectures with a native C based CUDA accelerated libary
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) Easy and efficient fine-tuning supporting various model architectures like Llama, Mixtral, Phi etc. for pre-training, supervised fine tuning, PPO, DPO, quantized fine tuning etc
- [torchtune](https://github.com/pytorch/torchtune) native pytorch LLM fine tuning fur llama architectures with QLoRA support
- [xtuner](https://github.com/InternLM/xtuner) fine tuning supporting llm, vlm pre training and fine tuning. deepspeed, ZeRO optimization, various architectures, QLoRA and LoRA support
- [Mergoo](https://github.com/Leeroo-AI/mergoo) merge multiple LLM experts and fine-tune them. Support for MoE, MoA for Llama1-3, Mistral, Phi3 and BERT models

## Merging & Quantization

- [mergekit](https://github.com/cg123/mergekit) Tools for merging pretrained large language models.
- [MergeLM](https://github.com/yule-BUAA/MergeLM) LLMs are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch
- [SLERP](https://github.com/Digitous/LLM-SLERP-Merge) Spherical Linear Interpolation Model Merging
- [AutoAWQ](https://github.com/casper-hansen/AutoAWQ)
- [AQLM](https://github.com/Vahe1994/AQLM) Extreme Compression of LLMs to 2bit via Additive Quantization to work with models of LLaMA, Mistral and Mixtral families [paper](https://arxiv.org/pdf/2401.06118.pdf)

# Resources

## Data sets

- [Alpaca-lora](https://github.com/tloen/alpaca-lora) instruction finetuned using Low Rank Adaption
- [codealpaca](https://github.com/sahil280114/codealpaca) Instruction training data set for code generation
- [LAION AI / Open-Assistant Dataset](https://huggingface.co/datasets/OpenAssistant/oasst1) (https://github.com/LAION-AI/Open-Assistant / https://projects.laion.ai/Open-Assistant/ / https://open-assistant.io)
- [ShareGPT pre-cleaned, English only](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) "unfiltered," and 2048 token split version of the ShareGPT dataset ready for finetuning
- [Vicuna ShareGPT pre-cleaned 90k conversation dataset](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/tree/main/HTML_cleaned_raw_dataset)
- [Vicuna ShareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)
- [GPTeacher](https://github.com/teknium1/GPTeacher)
- [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)
- [codealpaca 20k](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)
- [gpt3all pruned](https://huggingface.co/datasets/Nebulous/gpt4all_pruned)
- [gpt4all_prompt_generations_with_p3](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations_with_p3)
- [gpt4all_prompt_generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations)
- [alpaca-plus-gpt4all-without-p3](https://huggingface.co/datasets/magicgh/alpaca-plus-gpt4all-without-p3)
- [Alpaca dataset from Stanford, cleaned and curated](https://github.com/gururise/AlpacaDataCleaned)
- [Alpaca Chain of Thought](https://github.com/PhoebusSi/Alpaca-CoT) fine tuning dataset for EN and CN
- [PRESTO](https://ai.googleblog.com/2023/03/presto-multilingual-dataset-for-parsing.html) [paper](https://arxiv.org/pdf/2303.08954.pdf) Multilingual dataset for parsing realistic task-oriented dialogues by Google & University of Rochester, California, Santa Barbara, Columbia
- [RedPajama](https://www.together.xyz/blog/redpajama) Dataset and model similar to LLaMA but truly open source and ready for commercial use. [hf](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T)
- [BigCode The Stack](https://huggingface.co/datasets/bigcode/the-stack)
- [open-instruct-v1](https://huggingface.co/datasets/hakurei/open-instruct-v1)
- [awesome-instruction-dataset](https://github.com/yaodongC/awesome-instruction-dataset) list of instruction datasets by yadongC
- [The Embedding Archives](https://txt.cohere.com/embedding-archives-wikipedia/) Millions of Wikipedia Article Embeddings in multiple languages
- [Rereplit-finetuned-v1-3b & replit-code-v1-3b](https://twitter.com/Replit/status/1651344186715803648) outperforming all coding OSS models, gets released soon
- [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) an instruction-following dataset created using [Evol-Instruct](https://github.com/nlpxucan/evol-instruct), used to fine-tune [WizardLM](https://github.com/nlpxucan/WizardLM)
- [gpt4tools_71k.json](https://github.com/StevenGrove/GPT4Tools#Dataset) from GPT4Tools paper, having 71k instruction-following examples for sound/visual/text instructions
- [WizardVicuna 70k dataset](https://huggingface.co/datasets/junelee/wizard_vicuna_70k) used to fine tune [WizardVicuna](https://github.com/melodysdreamj/WizardVicunaLM)
- [Numbers every LLM Developer should know](https://github.com/ray-project/llm-numbers)
- [airoboros uncensored](https://huggingface.co/datasets/jondurbin/airoboros-uncensored)
- [CoT collection](https://github.com/kaistAI/CoT-Collection), [paper](https://arxiv.org/abs/2305.14045)
- [airoboros-gpt4](https://huggingface.co/datasets/jondurbin/airoboros-gpt4) fine-tuning dataset optimized for trivia, math, coding, closed context question answering, multiple choice, writing
- [fin-llama](https://huggingface.co/datasets/bavest/fin-llama-dataset) a LLaMA finetuned for finance, [code](https://github.com/Bavest/fin-llama), [model](https://huggingface.co/bavest/fin-llama-33b-merged)
- [dataset](https://github.com/AI4Finance-Foundation/FinNLP)
- [SlimPajama-627B](https://huggingface.co/datasets/cerebras/SlimPajama-627B) Deduplicated and cleaned RedPajama based dataset for higher information density and quality at lower token length
- [dolphin](https://huggingface.co/datasets/ehartford/dolphin) an attempt to replicate [Microsoft Orca](https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/) using FLANv2 augmented with GPT-4 and 3.5 completions
- [OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca) collection of augmented FLAN data with distributions aligned with the [orca paper](https://arxiv.org/abs/2306.02707)
- [ExpertQA](https://github.com/chaitanyamalaviya/expertqa) Expert-Curated Questions and Attributed Answers dataset with 2177 questions spanning 32 fields, along with verified answers and attributions for claims in the answers, [paper](https://arxiv.org/abs/2309.07852v1)
- [annas-archive](https://annas-archive.org/llm) world‚Äôs largest open-source open-data library. ‚≠êÔ∏è Mirrors Sci-Hub, Library Genesis, Z-Library, and more. üìà 22,052,322 books, 97,847,390 papers, 2,451,032 comics, 673,013 magazines 
- [RedPajama-Data-v2](https://together.ai/blog/redpajama-data-v2) Open Dataset with 30 Trillion Tokens for Training, [HF](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)

## Research

- [LLM Model Cards](https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs)
- [GPTs are GPTs: An early look at the labor market impact potential of LLMs](https://arxiv.org/abs/2303.10130)
- [ViperGPT](https://viper.cs.columbia.edu/) Visual Inference via Python Execution for reasoning
- [Emergent Abilities of LLMs](https://openreview.net/forum?id=yzkSU5zdwD) , [blog post](https://www.jasonwei.net/blog/emergence)
- [facts checker reinforcement](https://arxiv.org/abs/2302.12813)
- [LLaVA: Large Language and Vision Assistant, combining LLaMA with a visual model. Delta-weights released](https://llava-vl.github.io/)
- [Mass Editing Memory in a Transformer](https://memit.baulab.info/)
- [MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models](https://minigpt-4.github.io/)
- [WizardLM | Fine tuned LLaMA 7B with evolving instructions, outperforming chatGPT and Vicuna 13B on complex test instructions](https://arxiv.org/abs/2304.12244) ([code](https://github.com/nlpxucan/WizardLM), [delta weights](https://huggingface.co/victor123/WizardLM))
- [Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/abs/2304.11062)
- [AudioGPT | Understanding and Generating Speech, Music, Sound, and Talking Head](https://arxiv.org/abs/2304.12995) ([github](https://github.com/AIGC-Audio/AudioGPT), [hf space](https://huggingface.co/spaces/AIGC-Audio/AudioGPT))
- [Chameleon-llm](https://github.com/lupantech/chameleon-llm), a [paper](https://arxiv.org/abs/2304.09842) about Plug-and-Play Compositional Reasoning with GPT-4
- [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) share data generated by GPT-4 for building an instruction-following LLMs with supervised learning and reinforcement learning. [paper](https://arxiv.org/abs/2304.03277)
- [GPT4Tools](https://gpt4tools.github.io/) Teaching LLM to Use Tools via Self-instruct. [code](https://github.com/StevenGrove/GPT4Tools)
- [CAMEL](https://github.com/lightaime/camel): Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. [preprint paper](https://ghli.org/camel.pdf), [website](https://www.camel-ai.org/)
- [Poisoning Language Models During Instruction Tuning](https://arxiv.org/abs/2305.00944)
- [SparseGPT](https://arxiv.org/abs/2301.00774): Massive Language Models Can Be Accurately Pruned in One-Shot
- [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention](https://arxiv.org/abs/2303.16199)
- [Dromedary](https://arxiv.org/abs/2305.03047): Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision, [code](https://github.com/IBM/Dromedary), [weights](https://huggingface.co/zhiqings/dromedary-65b-lora-delta-v0)
- [Unlimiformer](https://arxiv.org/abs/2305.01625): transformer-based model that can process unlimited length input by offloading attention computation to a k-nearest-neighbor index, extending the capabilities of existing models like BART and Longformer without additional weights or code modifications. [code](https://github.com/abertsch72/unlimiformer)
- [Salesforce LAVIS](https://github.com/salesforce/lavis) provides a comprehensive Python library for language-vision intelligence research, including state-of-the-art models like BLIP-2 for vision-language pretraining and Img2LLM-VQA for visual question answering, alongside a unified interface
- [FLARE](https://arxiv.org/abs/2305.06983v1) an active retrieval augmented generation technique that iteratively predicts, retrieves, and refines content, improving the accuracy and efficiency of long-form text generation in language models
- [Hyena](https://hazyresearch.stanford.edu/blog/2023-03-07-hyena) a subquadratic-time layer that has the potential to significantly increase context length in sequence models, using a combination of long convolutions and gating. [Long Convs and Hyena implementations](https://github.com/hazyresearch/safari)
- [FastServe](https://arxiv.org/abs/2305.05920) an efficient distributed inference serving system for LLMs that minimizes job completion time using preemptive scheduling and efficient GPU memory management, built on NVIDIA FasterTransformer.
- [FrugalGPT](https://arxiv.org/abs/2305.05176) is a model that uses LLM cascade to optimize the performance and cost-efficiency of LLMs like GPT-4.
- [Landmark Attention](https://arxiv.org/abs/2305.16300) LLaMa 7B with 32k tokens. [Code](https://github.com/epfml/landmark-attention), llama7b diff [weights](https://huggingface.co/epfml/landmark-attention-llama7b-wdiff), merged llama7b [weights](https://huggingface.co/TheBloke/landmark-attention-llama7b-fp16)
- [QLORA](https://arxiv.org/abs/2305.14314) Efficient Finetuning of Quantized LLMs
- [Tree of Thoughts (ToT)](https://arxiv.org/abs/2305.10601) Enables exploration over text, improves strategic decision-making in language models. [Code](https://github.com/ysymyth/tree-of-thought-llm). Example [implementation](https://github.com/kyegomez/tree-of-thoughts), [discussion](https://github.com/kyegomez/tree-of-thoughts/pull/8)
- [MEGABYTE](https://arxiv.org/abs/2305.07185) Efficient multiscale decoder architecture for long-sequence modeling.
- [PandaGPT](http://arxiv.org/abs/2305.16355): [project page](https://panda-gpt.github.io/), [code](https://github.com/yxuansu/PandaGPT), [model](https://huggingface.co/openllmplayground/pandagpt_13b_max_len_400) combines ImageBind and Vicuna to understand and combine multimodal inputs from text, image, audio, depth, thermal, and IMU.
- [LIMA](https://arxiv.org/abs/2305.11206) Less Is More for Alignment. Shows fine-tuning with 1000 carefully curated prompts without reinforcement learning can outperforms GPT-4 in many cases
- [Gorilla](https://arxiv.org/abs/2305.15334) a finetuned LLaMA-based model that surpasses GPT-4 in writing API calls and reduces hallucination. [project](https://gorilla.cs.berkeley.edu/), [code](https://github.com/ShishirPatil/gorilla)
- [Voyager](https://arxiv.org/abs/2305.16291) Open-Ended Embodied Minecraft Agent using LLMs, [project](https://voyager.minedojo.org/), [code](https://github.com/MineDojo/Voyager)
- [BigTrans](https://huggingface.co/papers/2305.18098) llama adapted to multilingual translation over 100 languages, outperforming chatGPT in 8 language-pairs
- [BPT](https://arxiv.org/pdf/2305.19370.pdf) memory-efficient approach to processing long input sequences in Transformers
- [Lion](https://arxiv.org/abs/2305.12870) efficiently transfers knowledge from a closed-source LLM to an open-source student model
- [Undetectable Watermarks for Language Models](https://eprint.iacr.org/2023/763) using one-way functions
- [ALiBi](https://arxiv.org/abs/2108.12409) Train Short Test Long. Attention with Linear Biases Enables Input Length Extrapolation. [code](https://github.com/ofirpress/attention_with_linear_biases)
- [The Curse of Recursion](https://arxiv.org/abs/2305.17493): Training on Generated Data Makes Models Forget
- [Brainformers](https://arxiv.org/abs/2306.00008) a complex block for natural language processing that outperforms state-of-the-art Transformers in efficiency and quality
- [AWQ](https://arxiv.org/abs/2306.00978) Activation aware Weight Quantization for better LLM Compression and Acceleration, [code](https://github.com/mit-han-lab/llm-awq)
- [SpQR](https://arxiv.org/pdf/2306.03078) quantization by Tim Dettmers, [code](https://github.com/Vahe1994/SpQR), [twitter](https://twitter.com/Tim_Dettmers/status/1666076553665744896)
- [InternLM Technical report](https://github.com/InternLM/InternLM-techreport). A 104B parameters multilingual LLM with SOTA performance in knowledge understanding, reading comprehension, math and coding, outperforms open-source models and ChatGPT in 4 benchmarks
- [Naive Bayes-based Context Extension](https://github.com/bojone/NBCE/blob/main/README_en.md) NBCE extends context length of LLMs using Naive Bayes to 50k under 8\*A100
- [The Safari of Deep Signal Processing: Hyena and Beyond](https://hazyresearch.stanford.edu/blog/2023-06-08-hyena-safari)
- [Orca](https://arxiv.org/abs/2306.02707) Progressive Learning from Complex Explanation Traces of GPT-4. Fine-tunes small models by prompting large foundational models to explain their reasoning steps
- [How Far Can Camels Go?](https://arxiv.org/abs/2306.04751) optimizing instruction on open resources, [Tulu](https://huggingface.co/models?search=tulu) models released
- [FinGPT](https://arxiv.org/abs/2306.06031) open-source, accessible and cost efficient re-training for updating financial data inside LLMs for robo-advising, algorithmic trading, and other applications, [code](https://github.com/AI4Finance-Foundation/FinGPT), [dataset](https://github.com/AI4Finance-Foundation/FinNLP)
- [LongMem](https://arxiv.org/abs/2306.07174) proposes new framework, allowing for unlimited context length along with reduced GPU memory usage and faster inference speed. [Code](https://github.com/Victorwz/LongMem)
- [WizardCoder](https://arxiv.org/abs/2306.08568) empowers Coding Large Language Models with Evol-Instruct for complex instruction fine-tuning, outperforming open-source and closed LLMs on several benchmarks, [github repo](https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder), [model](https://huggingface.co/WizardLM/WizardCoder-15B-V1.0)
- [Infinigen](https://infinigen.org/) a procedural generator for foto realistic 3D scenes, based on Blender and running on GPUs, [paper](https://arxiv.org/abs/2306.09310), [github](https://github.com/princeton-vl/infinigen)
- [Do Large Language Models learn world models or just surface statistics](https://thegradient.pub/othello/)
- [Large Language Models Can Self-improve](https://www.lesswrong.com/posts/qwqowdhnMreKQvxLv/paper-large-language-models-can-self-improve-linkpost), [openreview.net](https://openreview.net/forum?id=NiEtU7blzN)
- [Switch Transformers](https://arxiv.org/abs/2101.03961) scaling to Trillion Parameter Models with efficient sparsity, a paper [speculated](https://news.ycombinator.com/item?id=36413296) to had an influence on GPT-4's undisclosed architecture using a sparsely activated Mixture of Experts (MoE) architecture
- [2022 & beyond Algorithms for efficient deep learning](https://archive.is/2XMvh) Google Research proposed various new architectures to scale LLMs further, including MoE
- [Wanda](https://arxiv.org/abs/2306.11695) Pruning by Weights and Activations a no-retraining pruning method for LLMs requires no retraining and outperforms existing methods, [code](https://github.com/locuslab/wanda)
- [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644) a 1.3B parameter LLM focusing on programming and coding from Microsoft, which outperforms all models on MBPP except GPT-4, ranks third on HumanEval above GPT-3.5, and exhibits emergent properties
- [RoPE](https://arxiv.org/abs/2104.09864v4) Enhanced Transformer with Rotary Position Embedding to extend context length
- [LongChat](https://lmsys.org/blog/2023-06-29-longchat/) a new level of extended context length up to 16K tokens, with two released models LongChat-7B and 13B
- [salesforce xgen](https://blog.salesforceairesearch.com/xgen/#training-details) a series of 7B LLMs with standard dense attention on up to 8K sequence length for up to 1.5T tokens
- [LongNet](https://arxiv.org/abs/2307.02486) Scaling transformers to 1 billion tokens
- [Lost in the Middle](https://arxiv.org/abs/2307.03172) recent LLMs have longer context and this paper finds that information is best retrieved at the beginning or the end, but mostly lost in the middle of long context
- [FoT](https://arxiv.org/abs/2307.03170) Focused Transformer with contrastive learning to achieve a 256k context length for passkey retrieval, [code](https://github.com/CStanKonrad/long_llama)
- [OpenLLMs](https://github.com/imoneoi/openchat) Less is More for Open-source Models, uses only ~6K GPT-4 conversations filtered for quality and achieves SOTA scores on Vicuna GPT-4 eval and AlpacaEval
- [CoDi](http://arxiv.org/abs/2305.11846) Any-to-Any Generation via Composable Diffusion
- [LEDITS](https://arxiv.org/abs/2307.00522) Real Image Editing with DDPM Inversion and Semantic Guidance, [demo](https://huggingface.co/spaces/editing-images/edit_friendly_ddpm_x_sega), [code](https://huggingface.co/spaces/editing-images/ledis/tree/main)
- [Mixture of Experts meets Instruction Tuning](https://arxiv.org/abs/2305.14705) MoE + Instruction Tuning is a winning combination for LLMs, likely being used for GPT-4
- [MoE Mixture of Experts LoRA Proof of Concept](https://colab.research.google.com/#fileId=https%3A//huggingface.co/datasets/crumb/Wizard-EvolInstruct70k-k4/blob/main/MoLora_7b_(PROOF_OF_CONCEPT).ipynb) by [AiCrumb](https://twitter.com/aicrumb/status/1681846805959528448), [reddit](https://www.reddit.com/r/LocalLLaMA/comments/154hwpu/mixture_of_lora/) discussion
- [LLM Attacks](https://arxiv.org/abs/2307.15043v1) Universal and Transferable Adversarial Attacks on Aligned Language Models, [code](https://github.com/llm-attacks/llm-attacks)
- [factool](https://arxiv.org/abs/2307.13528) framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT)
- [codellama](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/) Llama 2 fine tuned by meta for code completion, [github](https://github.com/facebookresearch/codellama)
- [Graph of Thoughts](https://arxiv.org/pdf/2308.09687.pdf) introducing Graph of Thoughts and comparing its performance to Chain of Thoughts and Tree of Thoughts, [code](https://github.com/spcl/graph-of-thoughts)
- [LIDA](https://github.com/microsoft/lida) Automatic Generation of Visualizations and Infographics using Large Language Models, [code](https://github.com/microsoft/lida)
- [Distilling step-by-step](https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html) Outperforming larger language models with less training data and smaller model sizes
- [LongLoRA](https://arxiv.org/pdf/2309.12307v1.pdf) Efficient Fine-tuning of Long-Context Large Language Models, [code](https://github.com/dvlab-research/longlora)
- [LLMLingua](https://arxiv.org/pdf/2310.06839v1.pdf) Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression, [code](https://github.com/microsoft/LLMLingua)
- [flagembedding](https://arxiv.org/abs/2310.07554v1), an embedding model for Retrieve Anything To Augment Large Language Models [code](https://github.com/flagopen/flagembedding)
- [mistral-7b](https://arxiv.org/abs/2310.06825v1) pretrained llm with 7 billion parameters outperforming Llama 2 13B using Grouped-Query-Attention, Sliding-Window Attention and Byte-Fallback BPE tokenizer, [weights](https://huggingface.co/mistralai)
- [CoVe](https://arxiv.org/abs/2309.11495) Chain-of-Verification Reduces Hallucination in Large Language Models, [implementation](https://github.com/hwchase17/chain-of-verification) in LangChain Expression Language, 
- [MemGPT](https://arxiv.org/abs/2310.08560) Towards LLMs as Operating Systems, perpetual chat bots with self editing memory, chat with your SQL database and local files etc, [code](https://github.com/cpacker/MemGPT)
- [microxcaling](https://arxiv.org/abs/2310.10537) AMD, Arm, Intel, Meta, Microsoft, NVIDIA, and Qualcomm Standardize Next-Generation Narrow Precision Data Format: Microscaling Data Formats for Deep Learning
- [AoT](https://arxiv.org/abs/2308.10379) Algorithm of Thoughts: Enhancing Exploration of Ideas in LLMs
- [Chain of Density Prompting](https://arxiv.org/abs/2309.04269) From Sparse to Dense: GPT-4 Summarization, [gpt-3.5 fine tune](https://jxnl.github.io/instructor/blog/2023/11/05/chain-of-density/) rivaling the quality of the original Chain of Density
- [Self-RAG](https://selfrag.github.io/) Learning to Retrieve, Generate and Critique through Self-Reflections outperforming ChatGPT and retrieval-augmented LLama2 Chat on six tasks, [selfrag finetuned llama2-13b](https://huggingface.co/selfrag/selfrag_llama2_13b), [mistral-7b finetune](https://huggingface.co/SciPhi/SciPhi-Self-RAG-Mistral-7B-32k)
- [LoRAShear](https://arxiv.org/abs/2310.18356) Efficient Large Language Model Structured Pruning and Knowledge Recovery
- [Making LLaMA SEE and Draw with SEED Tokenizer](https://arxiv.org/abs/2310.01218), Multi Modal fine tune of LLaMA with image generation, image recognition and text generation capabilities, [weights](https://huggingface.co/AILab-CVC/SEED), [github](https://ailab-cvc.github.io/seed/seed_llama.html)
- [BSM](https://arxiv.org/abs/2310.15123) Branch-Solve-Merge for LLMs enhancing coherence, planning, and task decomposition outperforming GPT-4 in some tasks
- [Skeleton-of-Thought](https://arxiv.org/abs/2307.15337) Large Language Models Can Do Parallel Decoding. SoT aims at decreasing the end-to-end generation latency of large language models 
- [ML-Bench](https://arxiv.org/abs/2311.09835) Large Language Models Leverage Open-source Libraries for Machine Learning Tasks, [page](https://ml-bench.github.io/), [code](https://github.com/gersteinlab/ML-bench)
- [QuIP#](https://cornell-relaxml.github.io/quip-sharp/) E8P 2-Bit Quantization of Large Language Models achieving near fp16 quantization performance
- [HQQ](https://mobiusml.github.io/hqq_blog/) Half-Quadratic Quantization for LLMs significantly accelerating quantization speed without requiring calibration data, outperforming existing methods in processing speed and memory efficiency. Sub 10GB VRAM Mixtral 8x7B implemented through [mixtral-offloading](https://github.com/dvmazur/mixtral-offloading), [guide](https://www.reddit.com/r/LocalLLaMA/comments/18w0j8y/mixtral_8x7b_on_10gb_vram_through_hqq_moe/?)
- [QMoE](https://arxiv.org/abs/2310.16795) Practical Sub-1-Bit Compression of Trillion-Parameter Models, [code](https://github.com/IST-DASLab/qmoe), [bitsandbytes sparse_MoE implementation](https://github.com/TimDettmers/bitsandbytes/tree/sparse_moe), [QMoE in llama.cpp](https://github.com/ggerganov/llama.cpp/issues/4445), [LoRa experts as alternative to QMoE](https://github.com/ggerganov/llama.cpp/issues/4611)
- [mamba](https://arxiv.org/abs/2312.00752) alternative to transformer architecture for LLMs using Linear-Time Sequence Modeling with Selective State Spaces [code](https://github.com/state-spaces/mamba)
- [StreamingLLM](http://arxiv.org/abs/2309.17453) Efficient Streaming Language Models with Attention Sinks for bigger Context Windows, [code](https://github.com/mit-han-lab/streaming-llm)
- [Chain of Abstraction](https://arxiv.org/abs/2401.17464) CoA A New Method for LLMs to Better Leverage Tools in Multi-Step Reasoning
- [The Era of 1-bit LLMs](https://arxiv.org/abs/2402.17764) All Large Language Models are in 1.58 Bits
- [Large World Model](https://largeworldmodel.github.io/) World Model on Million-Length Video and Language with Blockwise RingAttention by UC Berkley
- [Megalodon](https://arxiv.org/html/2404.08801v1) Meta's Efficient LLM Pretraining and Inference with Unlimited Context Length
- [Leave No Context Behind](https://arxiv.org/abs/2404.07143v1) Google's Efficient Infinite Context Transformers with Infini-attention
- [LongRoPE](https://arxiv.org/abs/2402.13753v1) Extending LLM Context Window Beyond 2 Million Tokens
- [KAN](https://arxiv.org/abs/2404.19756) Kolmogorov-Arnold Networks as promising alternatives to Multi-Layer Perceptrons (MLPs)
- [Sparse Llama](https://huggingface.co/papers/2405.03594) Cerebras and Neural Magic produces a 70% Smaller, 3x Faster, Full Accuracy [model](https://huggingface.co/neuralmagic), [page](https://www.cerebras.net/blog/introducing-sparse-llama-70-smaller-3x-faster-full-accuracy)
- [OSWorld](https://arxiv.org/abs/2404.07972) Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments
- [You Only Cache Once](https://arxiv.org/abs/2405.05254) Decoder-Decoder Architectures for Language Models
- [SOLAR](https://arxiv.org/abs/2312.15166) Scaling LLMs with Simple yet Effective Depth Up-Scaling to increase parameter count and continue pre-training, [SOLAR-10.7B](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)
- [TextGrad](https://arxiv.org/abs/2406.07496v1) allows users to enhance AI system components by backpropagating textual feedback provided by LLMs to optimize variables in computation graphs, utilizing a framework similar to PyTorch for various tasks.
- [Vision language models are blind](https://arxiv.org/abs/2407.06581) LLMs with Vision capabilities VLMs perform low on a new benchmark suite called BlindTest that is easy for humans but difficult for VLMs
- [SpreadsheetLLM](https://arxiv.org/abs/2407.09025v1) Encoding Spreadsheets for Large Language Models, introduces SheetCompressor, an innovative encoding framework for compressing spreadsheets to enhance LLM performance, achieving a state-of-the-art 78.9% F1 score, outperforming existing models.
- [Internet of Agents](https://arxiv.org/abs/2407.07061) creating a flexible and scalable platform for LLM-based multi-agent collaboration using an agent integration protocol, an instant-messaging-like architecture, and dynamic mechanisms for agent teaming and conversation flow control, code available
- [Mixture-of-Agents](https://arxiv.org/abs/2406.04692) MoA proposes a MoA methodology to leverage the strengths of multiple LLMs, achieving state-of-the-art performance using a layered architecture where each agent utilizes outputs from previous layers 
- [RAPTOR](https://arxiv.org/html/2401.18059v1) Recursive Abstractive Processing for Tree Organized Retrieval is a powerful indexing and retrieving technique clustering and summarizing text chunks in a hierarchical tree structure improving RAG quality significantly

# Other awesome resources

- [LLM Worksheet](https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=741531996) using an early CoT example by [randomfoo2](https://www.reddit.com/r/LocalAI/comments/12smsy9/list_of_public_foundational_models_fine_tunes/)
- [The full story of LLMs](https://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/)
- [Brief history of llama models](https://agi-sphere.com/llama-models/)
- [A timeline of transformer models](https://ai.v-gar.de/ml/transformer/timeline/)
- [Every front-end GUI client for ChatGPT API](https://github.com/billmei/every-chatgpt-gui)
- [LLMSurvey](https://github.com/rucaibox/llmsurvey) a collection of papers and resources including an LLM timeline
- [rentry.org/lmg_models](https://rentry.org/lmg_models) a list of llama derrivates and models
- [Timeline of AI and language models](https://lifearchitect.ai/timeline/) and [Model Comparison Sheet](https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs/edit#gid=1158069878) by Dr. Alan D. Thompson
- [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering) an evolving manual providing historical context, strategies, guidelines, and safety recommendations for building programmatic systems on OpenAI's GPT-4
- [LLMs Practical Guide](https://github.com/Mooler0410/LLMsPracticalGuide) actively curated collection of a timeline and guides for LLMs, providing a historical context and restrictions based on [this](https://arxiv.org/abs/2304.13712) paper and community contributions
- [LLMSurvey](https://github.com/RUCAIBox/LLMSurvey) based on [this](https://arxiv.org/abs/2303.18223) paper, builds a collection of further papers and resources related to LLMs including a timeline
- [LLaMAindex](https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec) can now use Document Summary Index for better QA performance compared to vectorDBs
- [ossinsight.io chat-gpt-apps](https://ossinsight.io/collections/chat-gpt-apps/) Updated list of top chatGPT related repositories
- [GenAI_LLM_timeline](https://github.com/hollobit/GenAI_LLM_timeline) Organized collection of papers, products, services and news of key events in Generative AI and LLMs with focus on ChatGPT
- [AIGC-progress](https://github.com/kinghuin/AIGC-progress) an awesome list of all things ml models and projects with daily updates
- [Things I'm learning while training SuperHOT](https://kaiokendev.github.io/til#extending-context-to-8k) talks about LiMA, Multi-Instruct and how to extend llama to 8k context size [github discussion](https://github.com/turboderp/exllama/issues/92#issuecomment-1603220170), [reddit discussion](https://www.reddit.com/r/LocalLLaMA/comments/14fgjqj/a_simple_way_to_extending_context_to_8k/)
- [LLM Utils](https://llm-utils.org/Home) An index of useful LLM related blog posts and tools
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) Latest Papers and Datasets on Multimodal Large Language Models, and Their Evaluation.
- [FourthBrain](https://github.com/FourthBrain) ML Edication backed by Andrew NG's AI fund, tutorials about LLM deployment, API Endpoint creation, MLOps, QLoRA fine tuning, etc.
- [companion-app](https://github.com/a16z-infra/companion-app) AI Getting Started template for developers using Clerk, Next.js, Pinecone, Langchain.js, OpenAI or Vicuna13b, Twilio
- [ppromptor](https://github.com/pikho/ppromptor) Prompt-Promptor is a Python library with a web UI designed to automatically generate and improve prompts for LLMs and consists of three agents: Proposer, Evaluator, and Analyzer. These agents work together with human experts to continuously improve the generated prompts
- [RAG Guide](https://github.com/ray-project/llm-applications/blob/main/notebooks/rag.ipynb) A Comprehensive Guide for Building RAG-based LLM Applications as a jupyter notebook, [HN](https://news.ycombinator.com/item?id=37505687)
- [RAG is more than just embedding search](https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/) learnings for building a good RAG-based LLM Application, [HN](https://news.ycombinator.com/item?id=37599873)
- [llm-agent-paper-list](https://github.com/woooodyy/llm-agent-paper-list) The paper list of the 86-page paper "The Rise and Potential of Large Language Model Based Agents: A Survey" by Zhiheng Xi et al., [paper](https://arxiv.org/abs/2309.07864)
- [awesome-ai-agents](https://github.com/e2b-dev/awesome-ai-agents) open and closed source agents by categories and industries
- [Azure OpenAI resources](https://github.com/kimtth/azure-openai-llm-vector-langchain) Azure OpenAI, LLMs +üåå Brief overview,ü¶ôSummary notes,üîéReferences, and üéãCheatsheet
- [alignment-handbook](https://github.com/huggingface/alignment-handbook) Huggingface's robust recipes for to align language models with human and AI preferences
- [llama-recipes](https://github.com/facebookresearch/llama-recipes) Llama 2 demo apps, recipes etc for RAG, Fine tuning, inference etc.
- [Something-of-THoughts in LLM Prompting](https://towardsdatascience.com/something-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390) Chain-of-Thoughts (CoT), Tree-of-Thoughts (ToT), Graph-of-Thoughts (GoT), and beyond, ‚Ä¶ What are these thoughts?
- [GPT-RAG](https://github.com/Azure/GPT-RAG) learnings when implementing Azure OpenAI with RAG at scale in a secure manner
- [AI and Open Source in 2023](https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023) a Summary of what happened in 2023 with all the learnings
- [convert text into graph of concepts](https://towardsdatascience.com/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a) Tutorial on how to use Knowledge Based QnA (KBQA) using Knowledge Graphs which can improve RAG context quality in some domains
- [Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners) 12 Lessons, Get Started Building with Generative AI from Microsoft
- [LLM Visualization](https://bbycroft.net/llm) Explaining how transformers work visually using nano-gpt
- [Visual explanations of core machine learning concepts](https://mlu-explain.github.io/) Visually learn how Neural networks, Regression, Reinforcement Learning, Random Forests and more concepts work
- [easily train a specialized llm](https://cameronrwolfe.substack.com/p/easily-train-a-specialized-llm-peft) PEFT, LoRA, QLoRA, LLaMA-Adapter, and More
- [promptbase](https://github.com/microsoft/promptbase) an evolving collection of resources, best practices, and example scripts for eliciting the best performance from foundation models
- [rag-survey](https://github.com/tongji-kgllm/rag-survey) an updated view on RAG in the wild, their approaches, taxonomy, tech stack and evolution [paper](https://arxiv.org/pdf/2312.10997.pdf)
- [Survey of Reasoning with Foundation Models](https://arxiv.org/pdf/2312.11562v4.pdf), [awesome reasoning list](https://github.com/reasoning-survey/awesome-reasoning-foundation-models)
- [llm-course](https://github.com/mlabonne/llm-course) Course to get into LLMs with roadmaps and notebooks covering Fundamentals, LLM-Scientist and LLM-Engineer roles
- [ML Papers of The Week](https://github.com/dair-ai/ML-Papers-of-the-Week) dair.ai curated list of weekly ML Papers
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) Illustrated Guide to Transformers- Step by Step Explanation
- [ai-exploits](https://github.com/protectai/ai-exploits) A collection of real world AI/ML exploits for responsibly disclosed vulnerabilities
- [AI Trends](https://epochai.org/trends) features key numbers and data visualizations in AI, related Epoch reports and other sources that showcase the change and growth in AI over time
- [Awesome-LLM-Inference](https://github.com/DefTruth/Awesome-LLM-Inference) curated list of Awesome LLM Inference Paper with codes, TensorRT-LLM, vLLM, streaming-llm, AWQ, SmoothQuant, WINT8/4, Continuous Batching, FlashAttention, PagedAttention etc.
- [fuck you, show me the prompt](https://hamel.dev/blog/posts/prompt/) Quickly understand inscrutable LLM frameworks by intercepting API calls.
- [awesome-generative-ai-guide](https://github.com/aishwaryanr/awesome-generative-ai-guide) with up to date links to papers, guides and resources
- [systematicall improving your rag](https://jxnl.co/writing/2024/05/22/systematically-improving-your-rag) blog about improving RAG systematically
- [fabric](https://github.com/danielmiessler/fabric) provides programmatically accessible prompt templates using a crowdsourced prompt DB 
- [Prompt Engineering Guide](https://www.promptingguide.ai/) compilation of various techniques like Few shot, chain of thought, tree of thoughts, tool using, ReAct and more to improve LLM quality via complex prompting

## Product Showcases

- [Opinionate.io AI Debating AI](https://opinionate.io/)
- [phind.com](phind.com) Developer Search Engine
- [Voice Q&A Assistant](https://github.com/hackingthemarkets/qa-assistant-eleven-labs-voice-cloning) using ChatGPT API, Embeddings, Gradio, Eleven Labs and Whisper
- [chatpdf](https://www.chatpdf.com/), Q&A for PDFs
- [ai collection](https://github.com/ai-collection/ai-collection) collecting startups and SaaS solutions using AI at its core
- [screenshot-to-code](https://github.com/abi/screenshot-to-code) this converts a website screenshot to approximated HTML/CSS code by using GPT-4-Vision
- [Outfit Anyone](https://github.com/HumanAIGC/OutfitAnyone) Ultra-high quality virtual try-on for Any Clothing and Any Person
- [llavavision](https://github.com/lxe/llavavision) simple "Be My Eyes" web app with a llama.cpp/llava backend explaining what the camera sees for blind assistance
- [pretzelai](https://github.com/pretzelai/pretzelai) modern fork of Jupyter Notebooks with AI code generation and editing, inline tab completion, sidebar chat and error fixing

## Benchmarking

### Leaderboards

- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) by HuggingFace
- [LMSys Chatbot Arena Leaderboard](https://chat.lmsys.org/?leaderboard), [blogpost](https://lmsys.org/blog/2023-05-03-arena/) is an anonymous benchmark platform for LLMs that features randomized battles in a crowdsourced manner. Careful: This just measures human preference, not accuracy or other factors
- [paperswithcode](https://paperswithcode.com/) LLM SOTA leaderboards, but usually just for foundation models
- [Can AI code](https://huggingface.co/spaces/mike-ravkine/can-ai-code-results) a self-evaluating interview for AI coding models. [code](https://github.com/the-crypt-keeper/can-ai-code)
- [C-Eval Benchmark](https://cevalbenchmark.com/static/leaderboard.html) Chinese focused LLM Eval Leaderboard
- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) Massive Text Embedding Benchmark (MTEB) Leaderboard (Vector Embeddings)
- [hallucination-leaderboard](https://huggingface.co/spaces/vectara/leaderboard) Hughes Hallucination Evaluation Model (HHEM) evaluates how often an LLM introduces hallucinations when summarizing a document [code](https://github.com/vectara/hallucination-leaderboard)
- [Big Code Models Leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard) evaluates base coding models
- [EvalPlus Leaderboard](https://evalplus.github.io/leaderboard.html) evaluates AI Coders with rigorous tests
- [Enterprise Scenarios Leaderboard](https://huggingface.co/spaces/PatronusAI/enterprise_scenarios_leaderboard) evaluates the performance of LLMs on real-world enterprise use cases, some of the test sets are closed source to prevent cheating (stale)
- [NP Hard Eval Leaderboard](https://huggingface.co/spaces/NPHardEval/NPHardEval-leaderboard) benchmark for assessing the reasoning abilities of LLMs by using NP Hard problems
- [Toqan Leaderboard](https://prollm.toqan.ai/leaderboard) Coding leaderboard with benchmarks for Coding Assistant, Q&A, Summarization, Entity extraction, Function calling and SQL
- [OpenCompass Leaderboard](https://rank.opencompass.org.cn/) Leaderboards with specific eval rankings for Medical, General and Law Benchmarks
- [NIAN](http://nian.llmonpy.ai/) Needle in a Needlestack for GPT-4o, GPT-4o-mini, Claude vs others
- [SEAL Leaderboards](https://scale.com/leaderboard) Expert-Driven Private Evaluations
- [AIR-bench](https://huggingface.co/spaces/AIR-Bench/leaderboard) Automated Heterogeneous Information Retrieval Benchmark focused on RAG and Retrieval tasks, automatically testing with synthetic random generated tasks
- [Leaderboards and benchmarks](https://huggingface.co/collections/clefourrier/leaderboards-and-benchmarks-64f99d2e11e92ca5568a7cce) collection of leaderboards and benchmarks for Text, vision, audio etc.
- [Berkeley Function-Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html) Leaderboard of LLMs following function calling instructions
- [Vision-Arena](https://huggingface.co/spaces/WildVision/vision-arena) Leaderboard for benchmarking Multimodal LLMs in the Wild for Vision and Text tasks.
- [Aider LLM Leaderboard](https://aider.chat/docs/leaderboards/) for Code Editing following instructions, not just code generation
- [RepoQA](https://evalplus.github.io/repoqa.html) Leaderboard evaluationg LLMs ability to find specific code in a long context code haystack
- [BigCodeBench-Hard](https://bigcode-bench.github.io/) Leaderboard evaluates LLMs with practical and challenging programming tasks, [HF Pages](https://huggingface.co/spaces/bigcode/bigcodebench-leaderboard)

### Benchmark Suites

- [Big-bench](https://github.com/google/BIG-bench) a collaborative benchmark featuring over 200 tasks for evaluating the capabilities of llms
- [Pythia](https://github.com/EleutherAI/pythia) interpretability analysis for autoregressive transformers during training
- [AlpacaEval](https://github.com/tatsu-lab/alpaca_eval) automatic evaluation for instruction following LLMs, validated against 20k human annotations, [reddit announcement](https://www.reddit.com/r/LocalLLaMA/comments/144l3t7/p_alpacaeval_an_automatic_evaluator_for/)
- [LMFlow Benchmark](https://github.com/OptimalScale/LMFlow#33-lmflow-benchmark) automatic evaluation framework for open source LLMs
- [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) framework for few-shot evaluation of autoregressive language models from EleutherAI
- [sql-eval](https://github.com/defog-ai/sql-eval) evaluation of LLM generated SQL queries
- [ragas](https://github.com/explodinggradients/ragas) RAG assessment: an evaluation framework for Retrieval Augmented Generation pipelines
- [ToolQA](https://github.com/night-chen/ToolQA) an evaluation framework for RAG and Tool LLM pipelines
- [LangCheck](https://github.com/citadel-ai/langcheck) Simple, Pythonic building blocks to evaluate LLM applications
- [PromethAI-Memory](https://github.com/topoteretes/PromethAI-Memory) Open-source framework for building and testing RAGs and Cognitive Architectures, designed for accuracy, transparency, and control
- [PromptBench](https://github.com/microsoft/promptbench) a Pytorch-based Python package for Evaluation of LLMs providing APIs
- [CanItEdit](https://github.com/nuprl/CanItEdit) Evaluating the Ability of Large Language Models to Follow Code Editing Instructions, [paper](https://arxiv.org/abs/2312.12450)
- [deepeval](https://github.com/confident-ai/deepeval) evaluation framework specialized for unit testing LLM applications based on metrics such as hallucination, answer relevancy, RAGAS, etc.
- [mlflow llm-evaluate](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html) use-case specific standard metrics and custom metrics, optional ground truth
- [AgentBoard](https://github.com/hkust-nlp/agentboard) Evaluation Board of Multi-turn LLM Agents
- [LLM-Uncertainty-Bench](https://github.com/smartyfh/llm-uncertainty-bench) Benchmarking LLMs via Uncertainty Quantification
- [OpenCompass](https://github.com/open-compass/opencompass) is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets
- [PHUDG3](https://github.com/deshwalmahesh/PHUDGE) Phi-3 as Scalable Judge. Evaluate your LLMs with an LLM
- [NIAN](https://github.com/llmonpy/needle-in-a-needlestack) Needle in a Needlestack because LLMs have improved and Needle in a Haystack has become too easy
- [beyondllm](https://github.com/aiplanethub/beyondllm) all-in-one toolkit for experimentation, evaluation, and deployment of Retrieval-Augmented Generation (RAG) systems
- [AIR-bench](https://github.com/AIR-Bench/AIR-Bench) Automated Heterogeneous Information Retrieval Benchmark focused on RAG and Retrieval tasks, automatically testing with synthetic random generated tasks
- [LLMSuite](https://github.com/giorgioroffo/large_language_models_open_suite) view code, run inferences, and measure performance with evaluation tasks
- [BlindTest](https://github.com/anguyen8/vision-llms-are-blind) Vision Language Model (VLM) benchmark to assess visual understanding capabilities
- [RepoQA](https://github.com/evalplus/repoqa) Evaluating Long-Context Code Understanding

## AI DevOps

- [Vicuna FastChat](https://github.com/lm-sys/FastChat)
- [SynapseML](https://github.com/microsoft/SynapseML) (previously known as MMLSpark),an open-source library that simplifies the creation of massively scalable machine learning (ML) pipelines
- [Colossal-AI](https://github.com/hpcaitech/ColossalAI) unified deep learning system that provides a collection of parallel components for distributed deep learning models. Provides data parallelism, pipeline parallelism, and tensor parallelism
- [OpenLLM](https://github.com/bentoml/OpenLLM) Run, deploy, and monitor open-source LLMs on any platform
- [skypilot](https://github.com/skypilot-org/skypilot) Run LLMs, AI, and Batch jobs on any cloud. Get maximum savings, highest GPU availability, and managed execution
- [ONNX Runtime](https://github.com/microsoft/onnxruntime) cross-platform inference and training machine-learning accelerator compatible with PyTorch, TensorFlow/Keras, scikit-learn, LightGBM, XGBoost, etc. and runs with different hardware, drivers, and operating systems
- [vllm](https://github.com/vllm-project/vllm) high-throughput and memory-efficient inference and serving engine for LLMs, [paper](https://arxiv.org/pdf/2309.06180v1.pdf)
- [openllmetry](https://github.com/traceloop/openllmetry) observability for your LLM application, based on OpenTelemetry
- [DeepSpeed-FastGen](https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen) High-throughput Text Generation for LLMs at 2x vLLM speeds
- [DeepSparse](https://github.com/neuralmagic/deepsparse) Sparsity-aware deep learning inference runtime for CPUs
- [dvc](https://github.com/iterative/dvc) ML Experiments Management with Git
- [S-LoRA](https://github.com/S-LoRA/S-LoRA) Serving Thousands of Concurrent LoRA Adapters
- [PowerInfer](https://github.com/sjtu-ipads/powerinfer) Fast LLM Serving with a Consumer-grade GPU leveraging activation locality, [PR on llama.cpp](https://github.com/ggerganov/llama.cpp/pull/4543), [issue on ollama](https://github.com/jmorganca/ollama/issues/1628)
- [TaskingAI](https://github.com/TaskingAI/TaskingAI) open source platform for AI-native application development
- [inferflow](https://github.com/inferflow/inferflow) LLM inference serving engine with support for Multi-GPU, Quantization supporting gguf, llama2, safetensors and many model families
- [LMDeploy](https://github.com/InternLM/lmdeploy multi-model, multi-machine, multi-card inference service for many models
- [powerinfer](https://github.com/sjtu-ipads/powerinfer) High-speed Model Inference Serving on Consumer GPU/CPU using activation locality for hot/cold neurons
- [lorax](https://github.com/predibase/lorax) Multi-LoRA inference server that scales to 1000s of fine-tuned LLMs
- [Geniusrise](https://github.com/geniusrise/geniusrise) AI microservices framework & ecosystem. Host inference APIs, schedule bulk inference and fine tune text, vision, audio and multi-modal models.
- [node-llmatic](https://huggingface.co/CohereForAI/c4ai-command-r-v01) self-hosted LLMs with an OpenAI compatible API
- [Nitro - Embeddable AI](https://github.com/janhq/nitro) An inference server on top of llama.cpp. OpenAI-compatible API, queue, & scaling. Embed a prod-ready, local inference engine in your apps. Powers Jan
- [gateway](https://github.com/missingstudio/gateway) Robust cloud-native AI Gateway and LLMOps infrastructure stack with routing, load balancing, fallback, analytics, caching, PII filter
- [pytorch-lightning](https://github.com/Lightning-AI/pytorch-lightning) Pretrain, finetune and deploy AI models on multiple GPUs, TPUs with zero code changes
- [text-generation-inference](https://github.com/huggingface/text-generation-inference) Huggingface's own Rust, Python and gRPC server for text gen inference providing an API endpoint, supporting Flash/Paged Attention, bitsandbytes, GPTQ, EETQ, AWQ, Logits, Logprobs, Speculation, Guidance
- [mistral.rs](https://github.com/EricLBuehler/mistral.rs) a fast LLM inference platform supporting inference on a variety of devices, quantization, and easy-to-use application with an Open-AI API compatible HTTP server and Python bindings
- [Text Generation Inference](https://huggingface.co/docs/text-generation-inference/en/index) deploy and serve popular LLMs with high-performance text generation, featuring optimizations like Tensor Parallelism, continuous batching, and quantization for efficient inference for GPUs and CPUs
- [gateway](https://github.com/Portkey-AI/gateway) local proxy and API multi model server with fallbacks, retries, load balancing
- [litellm](https://github.com/BerriAI/litellm) Use OpenAI API call format for any LLM backend (Local, Huggingface, Cohere, TogetherAI, Azure, Ollama, Replicate, Sagemaker, Anthropic, etc) as a load balancer

### Optimization

- [Petals](https://github.com/bigscience-workshop/petals)
- [FlexGen](https://github.com/FMInference/FlexGen) High-throughput Generative Inference of LLMs with a Single GPU
- [XLA](https://github.com/openxla/xla/) Accelerated Linear Algebra is a ML compiler for GPU, CPU and accelerators
- [zipslicer](https://github.com/kir-gadjello/zipslicer)
- [AITemplate](https://github.com/facebookincubator/AITemplate) a Python framework which renders neural network into high performance CUDA/HIP C++ code
- [Flash-attention](https://github.com/HazyResearch/flash-attention) Fast and memory-efficient exact attention
- [tokenmonster](https://github.com/alasdairforsythe/tokenmonster) ungreedy tokenizer increases inference speed and context-length by 35% for pre-training on new LLMs
- [LOMO](https://github.com/OpenLMLab/LOMO) fuses the gradient computation and the parameter update in one step to reduce memory usage enables the full parameter fine-tuning of a 7B model on a single RTX 3090
- [GPTFast](https://github.com/MDK8888/GPTFast) a set of techniques developed by the PyTorch Team to accelerate the inference speed of huggingface transformer models
- [KTransformers](https://github.com/kvcache-ai/ktransformers) KTransformers (QuickTransformers) is a framework for cutting-edge LLM Inference Optimizations

## Databases for ML

- [Pinecone](https://www.pinecone.io/) proprietary vector search for semantic search, recommendations and information retrieval
- [FAISS](https://github.com/facebookresearch/faiss) Library for Efficient Similarity Search and Clustering using vectors
- [Weaviate](https://github.com/weaviate/weaviate) open source vector DB for services like OpenAI, HF etc for text, image, Q&A etc.
- [vespa.ai](https://vespa.ai/) one of the only scalable vector DBs that supports multiple vectors per schema field
- [LanceDB](https://github.com/lancedb/lancedb) free open-source serverless vector DB with support for langchain, llamaindex and multi-modal data
- [Deeplake](https://github.com/activeloopai/deeplake) Vector Database for audio, text, vectors, video
- [milvus](https://github.com/milvus-io/milvus) open-source cloud-native vector DB focusing on embedding vectors converted from unstructured data
- [chroma](https://github.com/chroma-core/chroma) open-source embedding database
- [pgvector](https://github.com/pgvector/pgvector) open-source vector similarity search for Postgres.
- [chromem-go](https://github.com/philippgille/chromem-go) embeddable vector database for Go with Chroma-like interface and zero third-party dependencies. In-memory with optional persistence. 
- [txtai](https://github.com/neuml/txtai) All-in-one open-source embeddings database for semantic search, LLM orchestration and language model workflows
- [mindsdb](https://github.com/mindsdb/mindsdb) database for datascience and AI centered workloads like local LLM / OpenAI models access, text embeddings, forecasting etc.
- [haystackdb](https://github.com/carsonpo/haystackdb) on disk vector db which is 10x faster than FAISS in memory
- [vector-admin](https://github.com/Mintplex-Labs/vector-admin) universal tool suite for vector database management. Manage Pinecone, Chroma, Qdrant, Weaviate and more vector databases with ease

## Safety, Responsibility and Red Teaming

- [PyRIT](https://github.com/Azure/PyRIT) Python Risk Identification Tool for generative AI to automatically red team foundation models and apps
- [PurpleLlama](https://github.com/meta-llama/PurpleLlama) Cyber Security Eval, Llama Guard and Code Shield to assess and improve LLM security
